{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/everestso/summer25/blob/main/c166f25_02b_dqn_pong.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XtOuIKifmmyk"
   },
   "source": [
    "# Test 3 --- Final Test for 06.11.2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aqL9333gml9l",
    "outputId": "fab2076d-1255-4cac-904d-1bf4bba3a4bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /home/emil/miniconda3/envs/myenv1/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "Requirement already satisfied: gymnasium[accept-rom-license,atari] in /home/emil/miniconda3/envs/myenv1/lib/python3.13/site-packages (1.1.0)\n",
      "\u001b[33mWARNING: gymnasium 1.1.0 does not provide the extra 'accept-rom-license'\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: numpy>=1.21.0 in /home/emil/miniconda3/envs/myenv1/lib/python3.13/site-packages (from gymnasium[accept-rom-license,atari]) (2.3.2)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /home/emil/miniconda3/envs/myenv1/lib/python3.13/site-packages (from gymnasium[accept-rom-license,atari]) (3.1.1)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in /home/emil/miniconda3/envs/myenv1/lib/python3.13/site-packages (from gymnasium[accept-rom-license,atari]) (4.15.0)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in /home/emil/miniconda3/envs/myenv1/lib/python3.13/site-packages (from gymnasium[accept-rom-license,atari]) (0.0.4)\n",
      "Requirement already satisfied: ale_py>=0.9 in /home/emil/miniconda3/envs/myenv1/lib/python3.13/site-packages (from gymnasium[accept-rom-license,atari]) (0.11.2)\n",
      "/bin/bash: /home/emil/miniconda3/envs/myenv1/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "Requirement already satisfied: autorom in /home/emil/miniconda3/envs/myenv1/lib/python3.13/site-packages (0.6.1)\n",
      "Requirement already satisfied: click in /home/emil/miniconda3/envs/myenv1/lib/python3.13/site-packages (from autorom) (8.3.0)\n",
      "Requirement already satisfied: requests in /home/emil/miniconda3/envs/myenv1/lib/python3.13/site-packages (from autorom) (2.32.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/emil/miniconda3/envs/myenv1/lib/python3.13/site-packages (from requests->autorom) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/emil/miniconda3/envs/myenv1/lib/python3.13/site-packages (from requests->autorom) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/emil/miniconda3/envs/myenv1/lib/python3.13/site-packages (from requests->autorom) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/emil/miniconda3/envs/myenv1/lib/python3.13/site-packages (from requests->autorom) (2025.8.3)\n",
      "/bin/bash: /home/emil/miniconda3/envs/myenv1/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "Requirement already satisfied: stable-baselines3 in /home/emil/miniconda3/envs/myenv1/lib/python3.13/site-packages (2.7.0)\n",
      "Requirement already satisfied: gymnasium<1.3.0,>=0.29.1 in /home/emil/miniconda3/envs/myenv1/lib/python3.13/site-packages (from stable-baselines3) (1.1.0)\n",
      "Requirement already satisfied: numpy<3.0,>=1.20 in /home/emil/miniconda3/envs/myenv1/lib/python3.13/site-packages (from stable-baselines3) (2.3.2)\n",
      "Requirement already satisfied: torch<3.0,>=2.3 in /home/emil/miniconda3/envs/myenv1/lib/python3.13/site-packages (from stable-baselines3) (2.8.0)\n",
      "Requirement already satisfied: cloudpickle in /home/emil/miniconda3/envs/myenv1/lib/python3.13/site-packages (from stable-baselines3) (3.1.1)\n",
      "Requirement already satisfied: pandas in /home/emil/miniconda3/envs/myenv1/lib/python3.13/site-packages (from stable-baselines3) (2.3.2)\n",
      "Requirement already satisfied: matplotlib in /home/emil/miniconda3/envs/myenv1/lib/python3.13/site-packages (from stable-baselines3) (3.10.5)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in /home/emil/miniconda3/envs/myenv1/lib/python3.13/site-packages (from gymnasium<1.3.0,>=0.29.1->stable-baselines3) (4.15.0)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in /home/emil/miniconda3/envs/myenv1/lib/python3.13/site-packages (from gymnasium<1.3.0,>=0.29.1->stable-baselines3) (0.0.4)\n",
      "Requirement already satisfied: filelock in /home/emil/miniconda3/envs/myenv1/lib/python3.13/site-packages (from torch<3.0,>=2.3->stable-baselines3) (3.19.1)\n",
      "Requirement already satisfied: setuptools in /home/emil/miniconda3/envs/myenv1/lib/python3.13/site-packages (from torch<3.0,>=2.3->stable-baselines3) (78.1.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/emil/miniconda3/envs/myenv1/lib/python3.13/site-packages (from torch<3.0,>=2.3->stable-baselines3) (1.14.0)\n",
      "Requirement already satisfied: networkx in /home/emil/miniconda3/envs/myenv1/lib/python3.13/site-packages (from torch<3.0,>=2.3->stable-baselines3) (3.5)\n",
      "Requirement already satisfied: jinja2 in /home/emil/miniconda3/envs/myenv1/lib/python3.13/site-packages (from torch<3.0,>=2.3->stable-baselines3) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /home/emil/miniconda3/envs/myenv1/lib/python3.13/site-packages (from torch<3.0,>=2.3->stable-baselines3) (2025.9.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /home/emil/miniconda3/envs/myenv1/lib/python3.13/site-packages (from torch<3.0,>=2.3->stable-baselines3) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /home/emil/miniconda3/envs/myenv1/lib/python3.13/site-packages (from torch<3.0,>=2.3->stable-baselines3) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /home/emil/miniconda3/envs/myenv1/lib/python3.13/site-packages (from torch<3.0,>=2.3->stable-baselines3) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /home/emil/miniconda3/envs/myenv1/lib/python3.13/site-packages (from torch<3.0,>=2.3->stable-baselines3) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /home/emil/miniconda3/envs/myenv1/lib/python3.13/site-packages (from torch<3.0,>=2.3->stable-baselines3) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /home/emil/miniconda3/envs/myenv1/lib/python3.13/site-packages (from torch<3.0,>=2.3->stable-baselines3) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /home/emil/miniconda3/envs/myenv1/lib/python3.13/site-packages (from torch<3.0,>=2.3->stable-baselines3) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /home/emil/miniconda3/envs/myenv1/lib/python3.13/site-packages (from torch<3.0,>=2.3->stable-baselines3) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /home/emil/miniconda3/envs/myenv1/lib/python3.13/site-packages (from torch<3.0,>=2.3->stable-baselines3) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /home/emil/miniconda3/envs/myenv1/lib/python3.13/site-packages (from torch<3.0,>=2.3->stable-baselines3) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /home/emil/miniconda3/envs/myenv1/lib/python3.13/site-packages (from torch<3.0,>=2.3->stable-baselines3) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /home/emil/miniconda3/envs/myenv1/lib/python3.13/site-packages (from torch<3.0,>=2.3->stable-baselines3) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /home/emil/miniconda3/envs/myenv1/lib/python3.13/site-packages (from torch<3.0,>=2.3->stable-baselines3) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /home/emil/miniconda3/envs/myenv1/lib/python3.13/site-packages (from torch<3.0,>=2.3->stable-baselines3) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.4.0 in /home/emil/miniconda3/envs/myenv1/lib/python3.13/site-packages (from torch<3.0,>=2.3->stable-baselines3) (3.4.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/emil/miniconda3/envs/myenv1/lib/python3.13/site-packages (from sympy>=1.13.3->torch<3.0,>=2.3->stable-baselines3) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/emil/miniconda3/envs/myenv1/lib/python3.13/site-packages (from jinja2->torch<3.0,>=2.3->stable-baselines3) (3.0.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/emil/miniconda3/envs/myenv1/lib/python3.13/site-packages (from matplotlib->stable-baselines3) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/emil/miniconda3/envs/myenv1/lib/python3.13/site-packages (from matplotlib->stable-baselines3) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/emil/miniconda3/envs/myenv1/lib/python3.13/site-packages (from matplotlib->stable-baselines3) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/emil/miniconda3/envs/myenv1/lib/python3.13/site-packages (from matplotlib->stable-baselines3) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/emil/miniconda3/envs/myenv1/lib/python3.13/site-packages (from matplotlib->stable-baselines3) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /home/emil/miniconda3/envs/myenv1/lib/python3.13/site-packages (from matplotlib->stable-baselines3) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/emil/miniconda3/envs/myenv1/lib/python3.13/site-packages (from matplotlib->stable-baselines3) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/emil/miniconda3/envs/myenv1/lib/python3.13/site-packages (from matplotlib->stable-baselines3) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /home/emil/miniconda3/envs/myenv1/lib/python3.13/site-packages (from python-dateutil>=2.7->matplotlib->stable-baselines3) (1.17.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/emil/miniconda3/envs/myenv1/lib/python3.13/site-packages (from pandas->stable-baselines3) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/emil/miniconda3/envs/myenv1/lib/python3.13/site-packages (from pandas->stable-baselines3) (2025.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install gymnasium[atari,accept-rom-license]\n",
    "!pip install autorom\n",
    "!pip install stable-baselines3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Oi2qmVoVmxve",
    "outputId": "a95598af-349e-4206-f1c8-9b64ea32db5c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /home/emil/miniconda3/envs/myenv1/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "AutoROM will download the Atari 2600 ROMs.\n",
      "They will be installed to:\n",
      "\t/home/emil/miniconda3/envs/myenv1/lib/python3.13/site-packages/AutoROM/roms\n",
      "\n",
      "Existing ROMs will be overwritten.\n"
     ]
    }
   ],
   "source": [
    "!AutoROM --accept-license"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RQyqgMFzT-qi"
   },
   "source": [
    "# Install the Gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "_W_afhrzUAnp"
   },
   "outputs": [],
   "source": [
    "import ale_py\n",
    "import gymnasium as gym"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E0n7zQrALq7M"
   },
   "source": [
    "# Configure the model save drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "vlWPUjKfLv9y"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Models will be saved to: /home/emil/Desktop/project/models\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "save_dir = os.path.expanduser(\"./models\")\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "print(f\"âœ“ Models will be saved to: {os.path.abspath(save_dir)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "GPU AVAILABILITY CHECK\n",
      "==================================================\n",
      "PyTorch version: 2.8.0+cu128\n",
      "CUDA available: False\n",
      "CUDA version: 12.8\n",
      "Number of GPUs: 1\n",
      " GPU NOT DETECTED BY PYTORCH\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"GPU AVAILABILITY CHECK\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA version: {torch.version.cuda}\")\n",
    "print(f\"Number of GPUs: {torch.cuda.device_count()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU name: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
    "    print(\" GPU IS AVAILABLE FOR TRAINING!\")\n",
    "else:\n",
    "    print(\" GPU NOT DETECTED BY PYTORCH\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SAEvyoukL1T3"
   },
   "source": [
    "# Now Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "VCbjkLLSxCUN"
   },
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "import argparse\n",
    "import time\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import collections\n",
    "import typing as tt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.tensorboard.writer import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "dIJ32Rs6xJsV"
   },
   "outputs": [],
   "source": [
    "#dqn_model\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self, input_shape, n_actions):\n",
    "        super(DQN, self).__init__()\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(input_shape[0], 32, kernel_size=8, stride=4),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=4, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "        size = self.conv(torch.zeros(1, *input_shape)).size()[-1]\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(size, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, n_actions)\n",
    "        )\n",
    "    def forward(self, x: torch.ByteTensor):\n",
    "        x = x.float() / 255.0\n",
    "        return self.fc(self.conv(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "Vk2CtGcOBcQo"
   },
   "outputs": [],
   "source": [
    "#wrappers\n",
    "\n",
    "from gymnasium import spaces\n",
    "from stable_baselines3.common import atari_wrappers\n",
    "\n",
    "\n",
    "class ImageToPyTorch(gym.ObservationWrapper):\n",
    "    \"\"\"\n",
    "    ImageToPyTorch: Reorders image dimensions from (H, W, C) to (C, H, W)\n",
    "    for compatibility with PyTorch convolutional layers.\n",
    "    \"\"\"\n",
    "    def __init__(self, env):\n",
    "        super(ImageToPyTorch, self).__init__(env)\n",
    "        obs = self.observation_space\n",
    "        assert isinstance(obs, gym.spaces.Box)\n",
    "        assert len(obs.shape) == 3\n",
    "        new_shape = (obs.shape[-1], obs.shape[0], obs.shape[1])\n",
    "        self.observation_space = gym.spaces.Box(\n",
    "            low=obs.low.min(), high=obs.high.max(),\n",
    "            shape=new_shape, dtype=obs.dtype)\n",
    "\n",
    "    def observation(self, observation):\n",
    "        return np.moveaxis(observation, 2, 0)\n",
    "\n",
    "\n",
    "class BufferWrapper(gym.ObservationWrapper):\n",
    "    \"\"\"\n",
    "    BufferWrapper: Maintains a rolling window of the last `n_steps` frames\n",
    "    to give the agent a sense of temporal context.\n",
    "    \"\"\"\n",
    "    def __init__(self, env, n_steps):\n",
    "        super(BufferWrapper, self).__init__(env)\n",
    "        obs = env.observation_space\n",
    "        assert isinstance(obs, spaces.Box)\n",
    "        new_obs = gym.spaces.Box(\n",
    "            obs.low.repeat(n_steps, axis=0), obs.high.repeat(n_steps, axis=0),\n",
    "            dtype=obs.dtype)\n",
    "        self.observation_space = new_obs\n",
    "        self.buffer = collections.deque(maxlen=n_steps)\n",
    "\n",
    "    def reset(self, *, seed: tt.Optional[int] = None, options: tt.Optional[dict[str, tt.Any]] = None):\n",
    "        for _ in range(self.buffer.maxlen):\n",
    "            self.buffer.append(np.zeros_like(self.env.observation_space.low))\n",
    "        obs, extra = self.env.reset()\n",
    "        return self.observation(obs), extra\n",
    "\n",
    "    def observation(self, observation: np.ndarray) -> np.ndarray:\n",
    "        self.buffer.append(observation)\n",
    "        return np.concatenate(self.buffer)\n",
    "\n",
    "\n",
    "def make_env(env_name: str, n_steps=4, render_mode=None, **kwargs):\n",
    "    print(f\"Creating environment {env_name}\")\n",
    "    env = gym.make(env_name, render_mode=render_mode, **kwargs)\n",
    "    env = atari_wrappers.AtariWrapper(env, clip_reward=False, noop_max=0)\n",
    "    env = ImageToPyTorch(env)\n",
    "    env = BufferWrapper(env, n_steps=n_steps)\n",
    "    return env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "GvXPdjPCBxOd"
   },
   "outputs": [],
   "source": [
    "# Base Configuration\n",
    "DEFAULT_ENV_NAME = \"ALE/Pong-v5\"\n",
    "MEAN_REWARD_BOUND = 18\n",
    "\n",
    "GAMMA = 0.99\n",
    "BATCH_SIZE = 64\n",
    "REPLAY_SIZE = 50000\n",
    "LEARNING_RATE = 2.5e-4\n",
    "SYNC_TARGET_FRAMES = 5000\n",
    "REPLAY_START_SIZE = 10000\n",
    "\n",
    "SAVE_EPSILON = 0.5  # Only save if at least this much better\n",
    "EPSILON_DECAY_LAST_FRAME = 100000\n",
    "EPSILON_START = 1.0\n",
    "EPSILON_FINAL = 0.01\n",
    "\n",
    "# Tuple of tensors returned from a sampled minibatch in replay buffer\n",
    "State = np.ndarray\n",
    "Action = int\n",
    "BatchTensors = tt.Tuple[\n",
    "    torch.ByteTensor,           # current state\n",
    "    torch.LongTensor,           # actions\n",
    "    torch.Tensor,               # rewards\n",
    "    torch.BoolTensor,           # done || trunc\n",
    "    torch.ByteTensor            # next state\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "3FHvHNMrR9Sk"
   },
   "outputs": [],
   "source": [
    "# âš™ï¸ Fast Training Config for Quick Test Run\n",
    "MEAN_REWARD_BOUND = 18\n",
    "REPLAY_START_SIZE = 5000\n",
    "EPSILON_DECAY_LAST_FRAME = 100_000\n",
    "SYNC_TARGET_FRAMES = 1000\n",
    "\n",
    "# REPLAY_SIZE = 5000  # optional\n",
    "# BATCH_SIZE = 16     # optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "MkILCuT2OhBV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models will be saved to: /home/emil/Desktop/project/models\n",
      "Environment name: ALE_Pong-v5\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Save directory\n",
    "save_dir = \"./models\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# Safe filename\n",
    "env_name = DEFAULT_ENV_NAME\n",
    "safe_env_name = env_name.replace(\"/\", \"_\")\n",
    "\n",
    "print(f\"Models will be saved to: {os.path.abspath(save_dir)}\")\n",
    "print(f\"Environment name: {safe_env_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "uW4Bo-mcB6rc"
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Experience:\n",
    "    state: State\n",
    "    action: Action\n",
    "    reward: float\n",
    "    done_trunc: bool\n",
    "    new_state: State\n",
    "\n",
    "\n",
    "class ExperienceBuffer:\n",
    "    def __init__(self, capacity: int):\n",
    "        self.buffer = collections.deque(maxlen=capacity)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.buffer)\n",
    "\n",
    "    def append(self, experience: Experience):\n",
    "        self.buffer.append(experience)\n",
    "\n",
    "    def sample(self, batch_size: int) -> tt.List[Experience]:\n",
    "        indices = np.random.choice(len(self), batch_size, replace=False)\n",
    "        return [self.buffer[idx] for idx in indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "irJb4V32B-R8"
   },
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, env: gym.Env, exp_buffer: ExperienceBuffer):\n",
    "        self.env = env\n",
    "        self.exp_buffer = exp_buffer\n",
    "        self.state: tt.Optional[np.ndarray] = None\n",
    "        self._reset()\n",
    "\n",
    "    def _reset(self):\n",
    "        self.state, _ = self.env.reset()\n",
    "        self.total_reward = 0.0\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def play_step(self, net: DQN, device: torch.device,\n",
    "                  epsilon: float = 0.0) -> tt.Optional[float]:\n",
    "        done_reward = None\n",
    "\n",
    "        if np.random.random() < epsilon:\n",
    "            action = env.action_space.sample()\n",
    "        else:\n",
    "            state_v = torch.as_tensor(self.state).to(device)\n",
    "            state_v.unsqueeze_(0)\n",
    "            q_vals_v = net(state_v)\n",
    "            _, act_v = torch.max(q_vals_v, dim=1)\n",
    "            action = int(act_v.item())\n",
    "\n",
    "        # do step in the environment\n",
    "        new_state, reward, is_done, is_tr, _ = self.env.step(action)\n",
    "        self.total_reward += reward\n",
    "\n",
    "        exp = Experience(\n",
    "            state=self.state, action=action, reward=float(reward),\n",
    "            done_trunc=is_done or is_tr, new_state=new_state\n",
    "        )\n",
    "        self.exp_buffer.append(exp)\n",
    "        self.state = new_state\n",
    "        if is_done or is_tr:\n",
    "            done_reward = self.total_reward\n",
    "            self._reset()\n",
    "        return done_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "vHXmNr_wCBJm"
   },
   "outputs": [],
   "source": [
    "def batch_to_tensors(batch: tt.List[Experience], device: torch.device) -> BatchTensors:\n",
    "    states, actions, rewards, dones, new_state = [], [], [], [], []\n",
    "    for e in batch:\n",
    "        states.append(e.state)\n",
    "        actions.append(e.action)\n",
    "        rewards.append(e.reward)\n",
    "        dones.append(e.done_trunc)\n",
    "        new_state.append(e.new_state)\n",
    "    states_t = torch.as_tensor(np.asarray(states))\n",
    "    actions_t = torch.LongTensor(actions)\n",
    "    rewards_t = torch.FloatTensor(rewards)\n",
    "    dones_t = torch.BoolTensor(dones)\n",
    "    new_states_t = torch.as_tensor(np.asarray(new_state))\n",
    "    return states_t.to(device), actions_t.to(device), rewards_t.to(device), \\\n",
    "           dones_t.to(device),  new_states_t.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "-dbh0431CEXO"
   },
   "outputs": [],
   "source": [
    "def calc_loss(batch: tt.List[Experience], net: DQN, tgt_net: DQN,\n",
    "              device: torch.device) -> torch.Tensor:\n",
    "    states_t, actions_t, rewards_t, dones_t, new_states_t = batch_to_tensors(batch, device)\n",
    "\n",
    "    state_action_values = net(states_t).gather(\n",
    "        1, actions_t.unsqueeze(-1)\n",
    "    ).squeeze(-1)\n",
    "    with torch.no_grad():\n",
    "        next_state_values = tgt_net(new_states_t).max(1)[0]\n",
    "        next_state_values[dones_t] = 0.0\n",
    "        next_state_values = next_state_values.detach()\n",
    "\n",
    "    expected_state_action_values = next_state_values * GAMMA + rewards_t\n",
    "    return nn.MSELoss()(state_action_values, expected_state_action_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Q8gj-5woCXEB",
    "outputId": "ff17131f-3e00-417b-cb08-3298ec33510e",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating environment ALE/Pong-v5\n",
      "DQN(\n",
      "  (conv): Sequential(\n",
      "    (0): Conv2d(4, 32, kernel_size=(8, 8), stride=(4, 4))\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2))\n",
      "    (3): ReLU()\n",
      "    (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (5): ReLU()\n",
      "    (6): Flatten(start_dim=1, end_dim=-1)\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=3136, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=6, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A.L.E: Arcade Learning Environment (version 0.11.2+ecc1138)\n",
      "[Powered by Stella]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loop START\n",
      "205: done 1 games, reward -21.000, eps 1.00, speed 865.15 f/s, time 0.0 min\n",
      "ðŸ’¾ Model saved to: ./models/ALE_Pong-v5-best_-21-20251126-0859-test_epsdec100000_rs5000_sync1000.dat\n",
      "1561: done 7 games, reward -20.429, eps 0.98, speed 926.23 f/s, time 0.0 min\n",
      "ðŸ’¾ Model saved to: ./models/ALE_Pong-v5-best_-20-20251126-0859-test_epsdec100000_rs5000_sync1000.dat\n",
      "Best reward updated -21.000 -> -20.429\n",
      "56205: done 219 games, reward -19.900, eps 0.44, speed 209.70 f/s, time 3.8 min\n",
      "ðŸ’¾ Model saved to: ./models/ALE_Pong-v5-best_-19-20251126-0902-test_epsdec100000_rs5000_sync1000.dat\n",
      "Best reward updated -20.429 -> -19.900\n",
      "70922: done 259 games, reward -19.380, eps 0.29, speed 203.36 f/s, time 4.9 min\n",
      "ðŸ’¾ Model saved to: ./models/ALE_Pong-v5-best_-19-20251126-0904-test_epsdec100000_rs5000_sync1000.dat\n",
      "Best reward updated -19.900 -> -19.380\n",
      "83452: done 285 games, reward -18.860, eps 0.17, speed 200.74 f/s, time 6.0 min\n",
      "ðŸ’¾ Model saved to: ./models/ALE_Pong-v5-best_-18-20251126-0905-test_epsdec100000_rs5000_sync1000.dat\n",
      "Best reward updated -19.380 -> -18.860\n",
      "93652: done 302 games, reward -18.350, eps 0.06, speed 198.63 f/s, time 6.8 min\n",
      "ðŸ’¾ Model saved to: ./models/ALE_Pong-v5-best_-18-20251126-0905-test_epsdec100000_rs5000_sync1000.dat\n",
      "Best reward updated -18.860 -> -18.350\n",
      "102087: done 313 games, reward -17.790, eps 0.01, speed 185.47 f/s, time 7.6 min\n",
      "ðŸ’¾ Model saved to: ./models/ALE_Pong-v5-best_-17-20251126-0906-test_epsdec100000_rs5000_sync1000.dat\n",
      "Best reward updated -18.350 -> -17.790\n",
      "109405: done 321 games, reward -17.160, eps 0.01, speed 187.11 f/s, time 8.2 min\n",
      "ðŸ’¾ Model saved to: ./models/ALE_Pong-v5-best_-17-20251126-0907-test_epsdec100000_rs5000_sync1000.dat\n",
      "Best reward updated -17.790 -> -17.160\n",
      "116562: done 329 games, reward -16.500, eps 0.01, speed 181.96 f/s, time 8.9 min\n",
      "ðŸ’¾ Model saved to: ./models/ALE_Pong-v5-best_-16-20251126-0908-test_epsdec100000_rs5000_sync1000.dat\n",
      "Best reward updated -17.160 -> -16.500\n",
      "123100: done 337 games, reward -15.960, eps 0.01, speed 186.40 f/s, time 9.4 min\n",
      "ðŸ’¾ Model saved to: ./models/ALE_Pong-v5-best_-15-20251126-0908-test_epsdec100000_rs5000_sync1000.dat\n",
      "Best reward updated -16.500 -> -15.960\n",
      "129212: done 344 games, reward -15.430, eps 0.01, speed 191.82 f/s, time 10.0 min\n",
      "ðŸ’¾ Model saved to: ./models/ALE_Pong-v5-best_-15-20251126-0909-test_epsdec100000_rs5000_sync1000.dat\n",
      "Best reward updated -15.960 -> -15.430\n",
      "134902: done 351 games, reward -14.860, eps 0.01, speed 194.33 f/s, time 10.5 min\n",
      "ðŸ’¾ Model saved to: ./models/ALE_Pong-v5-best_-14-20251126-0909-test_epsdec100000_rs5000_sync1000.dat\n",
      "Best reward updated -15.430 -> -14.860\n",
      "142790: done 361 games, reward -14.340, eps 0.01, speed 189.25 f/s, time 11.1 min\n",
      "ðŸ’¾ Model saved to: ./models/ALE_Pong-v5-best_-14-20251126-0910-test_epsdec100000_rs5000_sync1000.dat\n",
      "Best reward updated -14.860 -> -14.340\n",
      "148842: done 369 games, reward -13.830, eps 0.01, speed 189.24 f/s, time 11.7 min\n",
      "ðŸ’¾ Model saved to: ./models/ALE_Pong-v5-best_-13-20251126-0910-test_epsdec100000_rs5000_sync1000.dat\n",
      "Best reward updated -14.340 -> -13.830\n",
      "152761: done 373 games, reward -13.260, eps 0.01, speed 196.68 f/s, time 12.0 min\n",
      "ðŸ’¾ Model saved to: ./models/ALE_Pong-v5-best_-13-20251126-0911-test_epsdec100000_rs5000_sync1000.dat\n",
      "Best reward updated -13.830 -> -13.260\n",
      "157628: done 379 games, reward -12.620, eps 0.01, speed 195.89 f/s, time 12.4 min\n",
      "ðŸ’¾ Model saved to: ./models/ALE_Pong-v5-best_-12-20251126-0911-test_epsdec100000_rs5000_sync1000.dat\n",
      "Best reward updated -13.260 -> -12.620\n",
      "164762: done 387 games, reward -12.000, eps 0.01, speed 194.52 f/s, time 13.0 min\n",
      "ðŸ’¾ Model saved to: ./models/ALE_Pong-v5-best_-12-20251126-0912-test_epsdec100000_rs5000_sync1000.dat\n",
      "Best reward updated -12.620 -> -12.000\n",
      "170166: done 393 games, reward -11.340, eps 0.01, speed 194.96 f/s, time 13.5 min\n",
      "ðŸ’¾ Model saved to: ./models/ALE_Pong-v5-best_-11-20251126-0912-test_epsdec100000_rs5000_sync1000.dat\n",
      "Best reward updated -12.000 -> -11.340\n",
      "175768: done 399 games, reward -10.770, eps 0.01, speed 195.15 f/s, time 14.0 min\n",
      "ðŸ’¾ Model saved to: ./models/ALE_Pong-v5-best_-10-20251126-0913-test_epsdec100000_rs5000_sync1000.dat\n",
      "Best reward updated -11.340 -> -10.770\n",
      "181866: done 405 games, reward -10.190, eps 0.01, speed 195.61 f/s, time 14.5 min\n",
      "ðŸ’¾ Model saved to: ./models/ALE_Pong-v5-best_-10-20251126-0913-test_epsdec100000_rs5000_sync1000.dat\n",
      "Best reward updated -10.770 -> -10.190\n",
      "187924: done 411 games, reward -9.640, eps 0.01, speed 184.77 f/s, time 15.1 min\n",
      "ðŸ’¾ Model saved to: ./models/ALE_Pong-v5-best_-9-20251126-0914-test_epsdec100000_rs5000_sync1000.dat\n",
      "Best reward updated -10.190 -> -9.640\n",
      "197762: done 423 games, reward -9.080, eps 0.01, speed 190.74 f/s, time 15.9 min\n",
      "ðŸ’¾ Model saved to: ./models/ALE_Pong-v5-best_-9-20251126-0915-test_epsdec100000_rs5000_sync1000.dat\n",
      "Best reward updated -9.640 -> -9.080\n",
      "207017: done 432 games, reward -8.480, eps 0.01, speed 185.58 f/s, time 16.8 min\n",
      "ðŸ’¾ Model saved to: ./models/ALE_Pong-v5-best_-8-20251126-0915-test_epsdec100000_rs5000_sync1000.dat\n",
      "Best reward updated -9.080 -> -8.480\n",
      "222083: done 449 games, reward -7.950, eps 0.01, speed 191.07 f/s, time 18.1 min\n",
      "ðŸ’¾ Model saved to: ./models/ALE_Pong-v5-best_-7-20251126-0917-test_epsdec100000_rs5000_sync1000.dat\n",
      "Best reward updated -8.480 -> -7.950\n",
      "236027: done 466 games, reward -7.430, eps 0.01, speed 189.03 f/s, time 19.3 min\n",
      "ðŸ’¾ Model saved to: ./models/ALE_Pong-v5-best_-7-20251126-0918-test_epsdec100000_rs5000_sync1000.dat\n",
      "Best reward updated -7.950 -> -7.430\n",
      "257511: done 490 games, reward -6.860, eps 0.01, speed 195.52 f/s, time 21.1 min\n",
      "ðŸ’¾ Model saved to: ./models/ALE_Pong-v5-best_-6-20251126-0920-test_epsdec100000_rs5000_sync1000.dat\n",
      "Best reward updated -7.430 -> -6.860\n",
      "274775: done 509 games, reward -6.290, eps 0.01, speed 194.03 f/s, time 22.6 min\n",
      "ðŸ’¾ Model saved to: ./models/ALE_Pong-v5-best_-6-20251126-0921-test_epsdec100000_rs5000_sync1000.dat\n",
      "Best reward updated -6.860 -> -6.290\n",
      "301715: done 538 games, reward -5.670, eps 0.01, speed 187.97 f/s, time 25.0 min\n",
      "ðŸ’¾ Model saved to: ./models/ALE_Pong-v5-best_-5-20251126-0924-test_epsdec100000_rs5000_sync1000.dat\n",
      "Best reward updated -6.290 -> -5.670\n",
      "311532: done 549 games, reward -5.110, eps 0.01, speed 187.18 f/s, time 25.9 min\n",
      "ðŸ’¾ Model saved to: ./models/ALE_Pong-v5-best_-5-20251126-0925-test_epsdec100000_rs5000_sync1000.dat\n",
      "Best reward updated -5.670 -> -5.110\n",
      "324534: done 564 games, reward -4.570, eps 0.01, speed 195.02 f/s, time 27.0 min\n",
      "ðŸ’¾ Model saved to: ./models/ALE_Pong-v5-best_-4-20251126-0926-test_epsdec100000_rs5000_sync1000.dat\n",
      "Best reward updated -5.110 -> -4.570\n",
      "346903: done 587 games, reward -3.970, eps 0.01, speed 186.13 f/s, time 29.0 min\n",
      "ðŸ’¾ Model saved to: ./models/ALE_Pong-v5-best_-3-20251126-0928-test_epsdec100000_rs5000_sync1000.dat\n",
      "Best reward updated -4.570 -> -3.970\n",
      "377032: done 619 games, reward -3.380, eps 0.01, speed 189.55 f/s, time 31.7 min\n",
      "ðŸ’¾ Model saved to: ./models/ALE_Pong-v5-best_-3-20251126-0930-test_epsdec100000_rs5000_sync1000.dat\n",
      "Best reward updated -3.970 -> -3.380\n",
      "400980: done 646 games, reward -2.800, eps 0.01, speed 190.47 f/s, time 33.7 min\n",
      "ðŸ’¾ Model saved to: ./models/ALE_Pong-v5-best_-2-20251126-0932-test_epsdec100000_rs5000_sync1000.dat\n",
      "Best reward updated -3.380 -> -2.800\n",
      "417477: done 664 games, reward -2.220, eps 0.01, speed 197.05 f/s, time 35.2 min\n",
      "ðŸ’¾ Model saved to: ./models/ALE_Pong-v5-best_-2-20251126-0934-test_epsdec100000_rs5000_sync1000.dat\n",
      "Best reward updated -2.800 -> -2.220\n",
      "422088: done 669 games, reward -1.710, eps 0.01, speed 197.20 f/s, time 35.6 min\n",
      "ðŸ’¾ Model saved to: ./models/ALE_Pong-v5-best_-1-20251126-0934-test_epsdec100000_rs5000_sync1000.dat\n",
      "Best reward updated -2.220 -> -1.710\n",
      "431446: done 679 games, reward -1.180, eps 0.01, speed 188.65 f/s, time 36.4 min\n",
      "ðŸ’¾ Model saved to: ./models/ALE_Pong-v5-best_-1-20251126-0935-test_epsdec100000_rs5000_sync1000.dat\n",
      "Best reward updated -1.710 -> -1.180\n",
      "459890: done 710 games, reward -0.570, eps 0.01, speed 195.48 f/s, time 38.9 min\n",
      "ðŸ’¾ Model saved to: ./models/ALE_Pong-v5-best_0-20251126-0938-test_epsdec100000_rs5000_sync1000.dat\n",
      "Best reward updated -1.180 -> -0.570\n",
      "470753: done 721 games, reward -0.010, eps 0.01, speed 187.28 f/s, time 39.8 min\n",
      "ðŸ’¾ Model saved to: ./models/ALE_Pong-v5-best_0-20251126-0939-test_epsdec100000_rs5000_sync1000.dat\n",
      "Best reward updated -0.570 -> -0.010\n",
      "926956: done 1205 games, reward 0.630, eps 0.01, speed 193.73 f/s, time 80.0 min\n",
      "ðŸ’¾ Model saved to: ./models/ALE_Pong-v5-best_0-20251126-1019-test_epsdec100000_rs5000_sync1000.dat\n",
      "Best reward updated -0.010 -> 0.630\n",
      "981922: done 1262 games, reward 1.140, eps 0.01, speed 194.64 f/s, time 84.8 min\n",
      "ðŸ’¾ Model saved to: ./models/ALE_Pong-v5-best_1-20251126-1023-test_epsdec100000_rs5000_sync1000.dat\n",
      "Best reward updated 0.630 -> 1.140\n",
      "1451703: done 1783 games, reward 1.780, eps 0.01, speed 195.65 f/s, time 125.5 min\n",
      "ðŸ’¾ Model saved to: ./models/ALE_Pong-v5-best_1-20251126-1104-test_epsdec100000_rs5000_sync1000.dat\n",
      "Best reward updated 1.140 -> 1.780\n",
      "1515756: done 1853 games, reward 2.290, eps 0.01, speed 197.94 f/s, time 131.1 min\n",
      "ðŸ’¾ Model saved to: ./models/ALE_Pong-v5-best_2-20251126-1110-test_epsdec100000_rs5000_sync1000.dat\n",
      "Best reward updated 1.780 -> 2.290\n",
      "1603654: done 1950 games, reward 2.810, eps 0.01, speed 193.92 f/s, time 138.6 min\n",
      "ðŸ’¾ Model saved to: ./models/ALE_Pong-v5-best_2-20251126-1117-test_epsdec100000_rs5000_sync1000.dat\n",
      "Best reward updated 2.290 -> 2.810\n",
      "1626584: done 1976 games, reward 3.360, eps 0.01, speed 191.22 f/s, time 140.6 min\n",
      "ðŸ’¾ Model saved to: ./models/ALE_Pong-v5-best_3-20251126-1119-test_epsdec100000_rs5000_sync1000.dat\n",
      "Best reward updated 2.810 -> 3.360\n",
      "2034862: done 2445 games, reward 3.880, eps 0.01, speed 191.88 f/s, time 175.9 min\n",
      "ðŸ’¾ Model saved to: ./models/ALE_Pong-v5-best_3-20251126-1155-test_epsdec100000_rs5000_sync1000.dat\n",
      "Best reward updated 3.360 -> 3.880\n",
      "2054164: done 2469 games, reward 4.450, eps 0.01, speed 197.86 f/s, time 177.6 min\n",
      "ðŸ’¾ Model saved to: ./models/ALE_Pong-v5-best_4-20251126-1156-test_epsdec100000_rs5000_sync1000.dat\n",
      "Best reward updated 3.880 -> 4.450\n",
      "2074412: done 2493 games, reward 5.010, eps 0.01, speed 190.89 f/s, time 179.3 min\n",
      "ðŸ’¾ Model saved to: ./models/ALE_Pong-v5-best_5-20251126-1158-test_epsdec100000_rs5000_sync1000.dat\n",
      "Best reward updated 4.450 -> 5.010\n",
      "2081076: done 2502 games, reward 5.560, eps 0.01, speed 194.51 f/s, time 179.9 min\n",
      "ðŸ’¾ Model saved to: ./models/ALE_Pong-v5-best_5-20251126-1159-test_epsdec100000_rs5000_sync1000.dat\n",
      "Best reward updated 5.010 -> 5.560\n",
      "2089888: done 2513 games, reward 6.110, eps 0.01, speed 189.08 f/s, time 180.6 min\n",
      "ðŸ’¾ Model saved to: ./models/ALE_Pong-v5-best_6-20251126-1159-test_epsdec100000_rs5000_sync1000.dat\n",
      "Best reward updated 5.560 -> 6.110\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 66\u001b[39m\n\u001b[32m     64\u001b[39m optimizer.zero_grad()\n\u001b[32m     65\u001b[39m batch = buffer.sample(BATCH_SIZE)\n\u001b[32m---> \u001b[39m\u001b[32m66\u001b[39m loss_t = calc_loss(batch, net, tgt_net, device)\n\u001b[32m     67\u001b[39m loss_t.backward()\n\u001b[32m     68\u001b[39m optimizer.step()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 3\u001b[39m, in \u001b[36mcalc_loss\u001b[39m\u001b[34m(batch, net, tgt_net, device)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcalc_loss\u001b[39m(batch: tt.List[Experience], net: DQN, tgt_net: DQN,\n\u001b[32m      2\u001b[39m               device: torch.device) -> torch.Tensor:\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     states_t, actions_t, rewards_t, dones_t, new_states_t = batch_to_tensors(batch, device)\n\u001b[32m      5\u001b[39m     state_action_values = net(states_t).gather(\n\u001b[32m      6\u001b[39m         \u001b[32m1\u001b[39m, actions_t.unsqueeze(-\u001b[32m1\u001b[39m)\n\u001b[32m      7\u001b[39m     ).squeeze(-\u001b[32m1\u001b[39m)\n\u001b[32m      8\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 14\u001b[39m, in \u001b[36mbatch_to_tensors\u001b[39m\u001b[34m(batch, device)\u001b[39m\n\u001b[32m     12\u001b[39m dones_t = torch.BoolTensor(dones)\n\u001b[32m     13\u001b[39m new_states_t = torch.as_tensor(np.asarray(new_state))\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m states_t.to(device), actions_t.to(device), rewards_t.to(device), \\\n\u001b[32m     15\u001b[39m        dones_t.to(device),  new_states_t.to(device)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# baseline DQN\n",
    "model_comment = f\"test_epsdec{EPSILON_DECAY_LAST_FRAME}_rs{REPLAY_START_SIZE}_sync{SYNC_TARGET_FRAMES}\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "env = make_env(env_name)\n",
    "net = DQN(env.observation_space.shape, env.action_space.n).to(device)\n",
    "tgt_net = DQN(env.observation_space.shape, env.action_space.n).to(device)\n",
    "writer = SummaryWriter(comment=f\"-{env_name}-{model_comment}\")\n",
    "print(net)\n",
    "\n",
    "buffer = ExperienceBuffer(REPLAY_SIZE)\n",
    "agent = Agent(env, buffer)\n",
    "epsilon = EPSILON_START\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr=LEARNING_RATE)\n",
    "total_rewards = []\n",
    "frame_idx = 0\n",
    "ts_frame = 0\n",
    "ts = time.time()\n",
    "best_m_reward = None\n",
    "\n",
    "print(\"loop START\")\n",
    "start_time = time.time()\n",
    "while True:\n",
    "    frame_idx += 1\n",
    "    epsilon = max(EPSILON_FINAL, EPSILON_START - frame_idx / EPSILON_DECAY_LAST_FRAME)\n",
    "\n",
    "    reward = agent.play_step(net, device, epsilon)\n",
    "    if reward is not None:\n",
    "        total_rewards.append(reward)\n",
    "        speed = (frame_idx - ts_frame) / (time.time() - ts)\n",
    "        elapsed = time.time() - start_time  # in seconds\n",
    "        ts_frame = frame_idx\n",
    "        ts = time.time()\n",
    "        m_reward = np.mean(total_rewards[-100:])\n",
    "        #  print(f\"{frame_idx}: done {len(total_rewards)} games, reward {m_reward:.3f}, \"\n",
    "        #      f\"eps {epsilon:.2f}, speed {speed:.2f} f/s, time {elapsed/60:.1f} min\")\n",
    "        writer.add_scalar(\"epsilon\", epsilon, frame_idx)\n",
    "        writer.add_scalar(\"speed\", speed, frame_idx)\n",
    "        writer.add_scalar(\"reward_100\", m_reward, frame_idx)\n",
    "        writer.add_scalar(\"reward\", reward, frame_idx)\n",
    "        if best_m_reward is None or m_reward > best_m_reward + SAVE_EPSILON:\n",
    "            print(f\"{frame_idx}: done {len(total_rewards)} games, reward {m_reward:.3f}, \"\n",
    "                f\"eps {epsilon:.2f}, speed {speed:.2f} f/s, time {elapsed/60:.1f} min\")\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d-%H%M\")\n",
    "            model_filename = f\"{safe_env_name}-best_{int(m_reward)}-{timestamp}-{model_comment}.dat\"\n",
    "\n",
    "            # Save to both paths <-----------------------\n",
    "            model_path = os.path.join(save_dir, model_filename)\n",
    "            torch.save(net.state_dict(), model_path)\n",
    "            print(f\"ðŸ’¾ Model saved to: {model_path}\")\n",
    "            # Adjust <-----------------------------------\n",
    "            if best_m_reward is not None:\n",
    "                print(f\"Best reward updated {best_m_reward:.3f} -> {m_reward:.3f}\")\n",
    "            best_m_reward = m_reward\n",
    "        if m_reward > MEAN_REWARD_BOUND:\n",
    "            print(\"Solved in %d frames!\" % frame_idx)\n",
    "            break\n",
    "    if len(buffer) < REPLAY_START_SIZE:\n",
    "        continue\n",
    "    if frame_idx % SYNC_TARGET_FRAMES == 0:\n",
    "        tgt_net.load_state_dict(net.state_dict())\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    batch = buffer.sample(BATCH_SIZE)\n",
    "    loss_t = calc_loss(batch, net, tgt_net, device)\n",
    "    loss_t.backward()\n",
    "    optimizer.step()\n",
    "env.close()\n",
    "writer.close()\n",
    "\n",
    "print(\"the END of the loop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Already closed or not defined (that's fine)\n",
      "\n",
      "======================================================================\n",
      "BASELINE DQN - FINAL RESULTS\n",
      "======================================================================\n",
      "Best Reward Achieved:  6\n",
      "Initial Reward:        -21\n",
      "Total Improvement:     +27 points\n",
      "Best Model:            ./models/ALE_Pong-v5-best_6-20251126-1159-test_epsdec100000_rs5000_sync1000.dat\n",
      "======================================================================\n",
      "\n",
      " Baseline DQN training complete!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "try:\n",
    "    env.close()\n",
    "    writer.close()\n",
    "    print(\" Environment and writer closed successfully\")\n",
    "except:\n",
    "    print(\" Already closed or not defined (that's fine)\")\n",
    "\n",
    "# Auto-find best BASELINE model in folder\n",
    "models_dir = \"./models\"\n",
    "best_reward = -float('inf')\n",
    "best_model_path = None\n",
    "\n",
    "for filename in os.listdir(models_dir):\n",
    "    if \"double_dqn\" not in filename and filename.endswith(\".dat\"):\n",
    "        match = re.search(r'best_(-?\\d+)-', filename)\n",
    "        if match:\n",
    "            reward = int(match.group(1))\n",
    "            if reward > best_reward:\n",
    "                best_reward = reward\n",
    "                best_model_path = os.path.join(models_dir, filename)\n",
    "\n",
    "# Use the reward from filename since training variables are gone\n",
    "final_reward = best_reward\n",
    "initial_reward = -21.0\n",
    "total_improvement = final_reward - initial_reward\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"BASELINE DQN - FINAL RESULTS\")\n",
    "print(\"=\"*70)\n",
    "print(\"Best Reward Achieved:  \" + str(final_reward))\n",
    "print(\"Initial Reward:        \" + str(int(initial_reward)))\n",
    "print(\"Total Improvement:     +\" + str(int(total_improvement)) + \" points\")\n",
    "print(\"Best Model:            \" + str(best_model_path))\n",
    "print(\"=\"*70)\n",
    "print(\"\\n Baseline DQN training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "======================================================================\n",
      "STEP 1: TESTING BASELINE DQN\n",
      "======================================================================\n",
      "Best model found: ./models/ALE_Pong-v5-best_6-20251126-1159-test_epsdec100000_rs5000_sync1000.dat\n",
      "Model reward: 6\n",
      "Creating environment ALE/Pong-v5\n",
      "\n",
      "Playing 10 test games...\n",
      "  Game  1:   4\n",
      "  Game  2:  16\n",
      "  Game  3:  14\n",
      "  Game  4:  12\n",
      "  Game  5:  12\n",
      "  Game  6:   7\n",
      "  Game  7:   7\n",
      "  Game  8:   7\n",
      "  Game  9:  -1\n",
      "  Game 10:   8\n",
      "\n",
      "======================================================================\n",
      "BASELINE DQN TEST RESULTS\n",
      "======================================================================\n",
      "Average Reward:    8.6\n",
      "Std Deviation:     4.78\n",
      "Best Game:         16\n",
      "Worst Game:        -1\n",
      "Games Won (>0):    9/10\n",
      "======================================================================\n",
      "ðŸ“Š Baseline DQN test average: 8.6\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# STEP 1: Test Baseline Agent\n",
    "# ============================================================\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device: \" + str(device))\n",
    "\n",
    "# Auto-find best baseline model in folder\n",
    "models_dir = \"./models\"\n",
    "best_reward = -float('inf')\n",
    "baseline_model_path = None\n",
    "\n",
    "for filename in os.listdir(models_dir):\n",
    "    if \"double_dqn\" not in filename and filename.endswith(\".dat\"):\n",
    "        match = re.search(r'best_(-?\\d+)-', filename)\n",
    "        if match:\n",
    "            reward = int(match.group(1))\n",
    "            if reward > best_reward:\n",
    "                best_reward = reward\n",
    "                baseline_model_path = os.path.join(models_dir, filename)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"STEP 1: TESTING BASELINE DQN\")\n",
    "print(\"=\"*70)\n",
    "print(\"Best model found: \" + str(baseline_model_path))\n",
    "print(\"Model reward: \" + str(best_reward))\n",
    "\n",
    "# Load baseline model\n",
    "test_env = make_env(DEFAULT_ENV_NAME)\n",
    "baseline_net = DQN(test_env.observation_space.shape, test_env.action_space.n).to(device)\n",
    "\n",
    "# FIXED: Add map_location to handle GPU/CPU mismatch\n",
    "baseline_net.load_state_dict(torch.load(baseline_model_path, map_location=device))\n",
    "baseline_net.eval()\n",
    "\n",
    "# Test on 10 games\n",
    "print(\"\\nPlaying 10 test games...\")\n",
    "baseline_rewards_list = []\n",
    "for game in range(10):\n",
    "    state, _ = test_env.reset()\n",
    "    episode_reward = 0\n",
    "    done = False\n",
    "    \n",
    "    while not done:\n",
    "        state_v = torch.tensor(np.array([state])).to(device)\n",
    "        with torch.no_grad():\n",
    "            q_vals = baseline_net(state_v)\n",
    "            action = q_vals.max(1)[1].item()\n",
    "        \n",
    "        state, reward, terminated, truncated, _ = test_env.step(action)\n",
    "        episode_reward += reward\n",
    "        done = terminated or truncated\n",
    "    \n",
    "    baseline_rewards_list.append(episode_reward)\n",
    "    print(\"  Game \" + str(game+1).rjust(2) + \": \" + str(int(episode_reward)).rjust(3))\n",
    "\n",
    "test_env.close()\n",
    "\n",
    "# Results\n",
    "baseline_test_avg = np.mean(baseline_rewards_list)\n",
    "baseline_test_std = np.std(baseline_rewards_list)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"BASELINE DQN TEST RESULTS\")\n",
    "print(\"=\"*70)\n",
    "print(\"Average Reward:    \" + str(round(baseline_test_avg, 2)))\n",
    "print(\"Std Deviation:     \" + str(round(baseline_test_std, 2)))\n",
    "print(\"Best Game:         \" + str(int(max(baseline_rewards_list))))\n",
    "print(\"Worst Game:        \" + str(int(min(baseline_rewards_list))))\n",
    "print(\"Games Won (>0):    \" + str(sum(1 for r in baseline_rewards_list if r > 0)) + \"/10\")\n",
    "print(\"=\"*70)\n",
    "print(\"ðŸ“Š Baseline DQN test average: \" + str(round(baseline_test_avg, 2)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "======================================================================\n",
      "STEP 2: RECORDING BASELINE VIDEOS\n",
      "======================================================================\n",
      "Using model: ./models/ALE_Pong-v5-best_6-20251126-1159-test_epsdec100000_rs5000_sync1000.dat\n",
      "\n",
      "[1/2] Recording early/random behavior...\n",
      "Creating environment ALE/Pong-v5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/emil/miniconda3/envs/myenv1/lib/python3.13/site-packages/gymnasium/wrappers/rendering.py:283: UserWarning: \u001b[33mWARN: Overwriting existing videos at /home/emil/Desktop/project/videos/baseline_early folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Recorded! Reward: -21\n",
      "\n",
      "[2/2] Recording trained baseline behavior...\n",
      "Creating environment ALE/Pong-v5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/emil/miniconda3/envs/myenv1/lib/python3.13/site-packages/gymnasium/wrappers/rendering.py:283: UserWarning: \u001b[33mWARN: Overwriting existing videos at /home/emil/Desktop/project/videos/baseline_learned folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Recorded! Reward: 12\n",
      "\n",
      "======================================================================\n",
      "BASELINE VIDEOS COMPLETE\n",
      "======================================================================\n",
      "Location:\n",
      "  Early:   ./videos/baseline_early/\n",
      "  Learned: ./videos/baseline_learned/\n",
      "\n",
      "Reward Comparison:\n",
      "  Random:       -21\n",
      "  Trained:      12\n",
      "  Improvement:  33 points\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# STEP 2: Record Baseline Videos\n",
    "# ============================================================\n",
    "from gymnasium.wrappers import RecordVideo\n",
    "import os\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device: \" + str(device))\n",
    "\n",
    "# Create video directories\n",
    "os.makedirs('./videos/baseline_early', exist_ok=True)\n",
    "os.makedirs('./videos/baseline_learned', exist_ok=True)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"STEP 2: RECORDING BASELINE VIDEOS\")\n",
    "print(\"=\"*70)\n",
    "print(\"Using model: \" + str(baseline_model_path))\n",
    "\n",
    "# VIDEO 1: Early/Random Behavior\n",
    "print(\"\\n[1/2] Recording early/random behavior...\")\n",
    "video_env = make_env(DEFAULT_ENV_NAME, render_mode=\"rgb_array\")\n",
    "video_env = RecordVideo(\n",
    "    video_env,\n",
    "    video_folder='./videos/baseline_early',\n",
    "    episode_trigger=lambda x: x == 0,\n",
    "    name_prefix=\"baseline-early\"\n",
    ")\n",
    "\n",
    "state, _ = video_env.reset()\n",
    "done = False\n",
    "early_reward = 0\n",
    "while not done:\n",
    "    action = video_env.action_space.sample()  # Random\n",
    "    state, reward, terminated, truncated, _ = video_env.step(action)\n",
    "    early_reward += reward\n",
    "    done = terminated or truncated\n",
    "video_env.close()\n",
    "print(\"       Recorded! Reward: \" + str(int(early_reward)))\n",
    "\n",
    "# VIDEO 2: Trained Baseline Behavior\n",
    "print(\"\\n[2/2] Recording trained baseline behavior...\")\n",
    "video_env = make_env(DEFAULT_ENV_NAME, render_mode=\"rgb_array\")\n",
    "video_env = RecordVideo(\n",
    "    video_env,\n",
    "    video_folder='./videos/baseline_learned',\n",
    "    episode_trigger=lambda x: x == 0,\n",
    "    name_prefix=\"baseline-learned\"\n",
    ")\n",
    "\n",
    "baseline_net = DQN(video_env.observation_space.shape, video_env.action_space.n).to(device)\n",
    "\n",
    "# FIXED: Add map_location to handle GPU/CPU mismatch\n",
    "baseline_net.load_state_dict(torch.load(baseline_model_path, map_location=device))\n",
    "baseline_net.eval()\n",
    "\n",
    "state, _ = video_env.reset()\n",
    "done = False\n",
    "learned_reward = 0\n",
    "while not done:\n",
    "    state_v = torch.tensor(np.array([state])).to(device)\n",
    "    with torch.no_grad():\n",
    "        q_vals = baseline_net(state_v)\n",
    "        action = q_vals.max(1)[1].item()\n",
    "    \n",
    "    state, reward, terminated, truncated, _ = video_env.step(action)\n",
    "    learned_reward += reward\n",
    "    done = terminated or truncated\n",
    "video_env.close()\n",
    "print(\"       Recorded! Reward: \" + str(int(learned_reward)))\n",
    "\n",
    "# Summary\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"BASELINE VIDEOS COMPLETE\")\n",
    "print(\"=\"*70)\n",
    "print(\"Location:\")\n",
    "print(\"  Early:   ./videos/baseline_early/\")\n",
    "print(\"  Learned: ./videos/baseline_learned/\")\n",
    "print(\"\\nReward Comparison:\")\n",
    "print(\"  Random:       \" + str(int(early_reward)))\n",
    "print(\"  Trained:      \" + str(int(learned_reward)))\n",
    "print(\"  Improvement:  \" + str(int(learned_reward - early_reward)) + \" points\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_dDQN(batch: tt.List[Experience], net: DQN, tgt_net: DQN,\n",
    "              device: torch.device) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Double DQN loss calculation.\n",
    "    Uses online network for action selection, target network for evaluation.\n",
    "    \"\"\"\n",
    "    states_t, actions_t, rewards_t, dones_t, new_states_t = batch_to_tensors(batch, device)\n",
    "\n",
    "    # Current Q-values for taken actions\n",
    "    state_action_values = net(states_t).gather(\n",
    "        1, actions_t.unsqueeze(-1)\n",
    "    ).squeeze(-1)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # DOUBLE DQN CHANGE: Use online network to select best action\n",
    "        next_state_actions = net(new_states_t).max(1)[1]\n",
    "        \n",
    "        # Use target network to evaluate those actions\n",
    "        next_state_values = tgt_net(new_states_t).gather(\n",
    "            1, next_state_actions.unsqueeze(-1)\n",
    "        ).squeeze(-1)\n",
    "        \n",
    "        next_state_values[dones_t] = 0.0\n",
    "        next_state_values = next_state_values.detach()\n",
    "\n",
    "    expected_state_action_values = next_state_values * GAMMA + rewards_t\n",
    "    return nn.MSELoss()(state_action_values, expected_state_action_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating environment ALE/Pong-v5\n",
      "DQN(\n",
      "  (conv): Sequential(\n",
      "    (0): Conv2d(4, 32, kernel_size=(8, 8), stride=(4, 4))\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2))\n",
      "    (3): ReLU()\n",
      "    (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (5): ReLU()\n",
      "    (6): Flatten(start_dim=1, end_dim=-1)\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=3136, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=6, bias=True)\n",
      "  )\n",
      ")\n",
      "loop START\n",
      "253: done 1 games, reward -20.000, eps 1.00, speed 847.04 f/s, time 0.0 min\n",
      "ðŸ’¾ Model saved to: ./models/ALE_Pong-v5-best_-20-20251126-1235-double_dqn_epsdec100000_rs5000_sync1000.dat\n",
      "64357: done 246 games, reward -19.490, eps 0.36, speed 190.48 f/s, time 4.8 min\n",
      "ðŸ’¾ Model saved to: ./models/ALE_Pong-v5-best_-19-20251126-1240-double_dqn_epsdec100000_rs5000_sync1000.dat\n",
      "Best reward updated -20.000 -> -19.490\n",
      "76663: done 277 games, reward -18.980, eps 0.23, speed 184.50 f/s, time 5.9 min\n",
      "ðŸ’¾ Model saved to: ./models/ALE_Pong-v5-best_-18-20251126-1241-double_dqn_epsdec100000_rs5000_sync1000.dat\n",
      "Best reward updated -19.490 -> -18.980\n",
      "82901: done 291 games, reward -18.440, eps 0.17, speed 189.44 f/s, time 6.5 min\n",
      "ðŸ’¾ Model saved to: ./models/ALE_Pong-v5-best_-18-20251126-1242-double_dqn_epsdec100000_rs5000_sync1000.dat\n",
      "Best reward updated -18.980 -> -18.440\n",
      "89843: done 305 games, reward -17.890, eps 0.10, speed 179.59 f/s, time 7.1 min\n",
      "ðŸ’¾ Model saved to: ./models/ALE_Pong-v5-best_-17-20251126-1242-double_dqn_epsdec100000_rs5000_sync1000.dat\n",
      "Best reward updated -18.440 -> -17.890\n",
      "96067: done 315 games, reward -17.340, eps 0.04, speed 175.28 f/s, time 7.7 min\n",
      "ðŸ’¾ Model saved to: ./models/ALE_Pong-v5-best_-17-20251126-1243-double_dqn_epsdec100000_rs5000_sync1000.dat\n",
      "Best reward updated -17.890 -> -17.340\n",
      "101217: done 322 games, reward -16.770, eps 0.01, speed 179.33 f/s, time 8.2 min\n",
      "ðŸ’¾ Model saved to: ./models/ALE_Pong-v5-best_-16-20251126-1243-double_dqn_epsdec100000_rs5000_sync1000.dat\n",
      "Best reward updated -17.340 -> -16.770\n",
      "105614: done 328 games, reward -16.190, eps 0.01, speed 179.55 f/s, time 8.6 min\n",
      "ðŸ’¾ Model saved to: ./models/ALE_Pong-v5-best_-16-20251126-1244-double_dqn_epsdec100000_rs5000_sync1000.dat\n",
      "Best reward updated -16.770 -> -16.190\n",
      "112784: done 339 games, reward -15.690, eps 0.01, speed 173.88 f/s, time 9.3 min\n",
      "ðŸ’¾ Model saved to: ./models/ALE_Pong-v5-best_-15-20251126-1244-double_dqn_epsdec100000_rs5000_sync1000.dat\n",
      "Best reward updated -16.190 -> -15.690\n",
      "117222: done 345 games, reward -15.170, eps 0.01, speed 179.45 f/s, time 9.7 min\n",
      "ðŸ’¾ Model saved to: ./models/ALE_Pong-v5-best_-15-20251126-1245-double_dqn_epsdec100000_rs5000_sync1000.dat\n",
      "Best reward updated -15.690 -> -15.170\n",
      "123383: done 354 games, reward -14.610, eps 0.01, speed 178.97 f/s, time 10.3 min\n",
      "ðŸ’¾ Model saved to: ./models/ALE_Pong-v5-best_-14-20251126-1245-double_dqn_epsdec100000_rs5000_sync1000.dat\n",
      "Best reward updated -15.170 -> -14.610\n",
      "128405: done 362 games, reward -14.090, eps 0.01, speed 169.91 f/s, time 10.7 min\n",
      "ðŸ’¾ Model saved to: ./models/ALE_Pong-v5-best_-14-20251126-1246-double_dqn_epsdec100000_rs5000_sync1000.dat\n",
      "Best reward updated -14.610 -> -14.090\n",
      "135292: done 372 games, reward -13.530, eps 0.01, speed 179.37 f/s, time 11.4 min\n",
      "ðŸ’¾ Model saved to: ./models/ALE_Pong-v5-best_-13-20251126-1246-double_dqn_epsdec100000_rs5000_sync1000.dat\n",
      "Best reward updated -14.090 -> -13.530\n",
      "141239: done 381 games, reward -12.980, eps 0.01, speed 179.65 f/s, time 11.9 min\n",
      "ðŸ’¾ Model saved to: ./models/ALE_Pong-v5-best_-12-20251126-1247-double_dqn_epsdec100000_rs5000_sync1000.dat\n",
      "Best reward updated -13.530 -> -12.980\n",
      "150141: done 394 games, reward -12.410, eps 0.01, speed 177.02 f/s, time 12.8 min\n",
      "ðŸ’¾ Model saved to: ./models/ALE_Pong-v5-best_-12-20251126-1248-double_dqn_epsdec100000_rs5000_sync1000.dat\n",
      "Best reward updated -12.980 -> -12.410\n",
      "155863: done 402 games, reward -11.890, eps 0.01, speed 173.46 f/s, time 13.3 min\n",
      "ðŸ’¾ Model saved to: ./models/ALE_Pong-v5-best_-11-20251126-1248-double_dqn_epsdec100000_rs5000_sync1000.dat\n",
      "Best reward updated -12.410 -> -11.890\n",
      "179828: done 434 games, reward -11.280, eps 0.01, speed 176.33 f/s, time 15.6 min\n",
      "ðŸ’¾ Model saved to: ./models/ALE_Pong-v5-best_-11-20251126-1251-double_dqn_epsdec100000_rs5000_sync1000.dat\n",
      "Best reward updated -11.890 -> -11.280\n",
      "196787: done 458 games, reward -10.770, eps 0.01, speed 173.09 f/s, time 17.2 min\n",
      "ðŸ’¾ Model saved to: ./models/ALE_Pong-v5-best_-10-20251126-1252-double_dqn_epsdec100000_rs5000_sync1000.dat\n",
      "Best reward updated -11.280 -> -10.770\n",
      "217890: done 487 games, reward -10.180, eps 0.01, speed 166.32 f/s, time 19.3 min\n",
      "ðŸ’¾ Model saved to: ./models/ALE_Pong-v5-best_-10-20251126-1254-double_dqn_epsdec100000_rs5000_sync1000.dat\n",
      "Best reward updated -10.770 -> -10.180\n",
      "230855: done 503 games, reward -9.600, eps 0.01, speed 174.04 f/s, time 20.5 min\n",
      "ðŸ’¾ Model saved to: ./models/ALE_Pong-v5-best_-9-20251126-1256-double_dqn_epsdec100000_rs5000_sync1000.dat\n",
      "Best reward updated -10.180 -> -9.600\n",
      "244693: done 521 games, reward -9.060, eps 0.01, speed 170.05 f/s, time 21.9 min\n",
      "ðŸ’¾ Model saved to: ./models/ALE_Pong-v5-best_-9-20251126-1257-double_dqn_epsdec100000_rs5000_sync1000.dat\n",
      "Best reward updated -9.600 -> -9.060\n",
      "265335: done 547 games, reward -8.530, eps 0.01, speed 175.55 f/s, time 24.0 min\n",
      "ðŸ’¾ Model saved to: ./models/ALE_Pong-v5-best_-8-20251126-1259-double_dqn_epsdec100000_rs5000_sync1000.dat\n",
      "Best reward updated -9.060 -> -8.530\n",
      "281484: done 568 games, reward -8.000, eps 0.01, speed 175.59 f/s, time 25.5 min\n",
      "ðŸ’¾ Model saved to: ./models/ALE_Pong-v5-best_-8-20251126-1301-double_dqn_epsdec100000_rs5000_sync1000.dat\n",
      "Best reward updated -8.530 -> -8.000\n",
      "294400: done 584 games, reward -7.370, eps 0.01, speed 163.05 f/s, time 26.8 min\n",
      "ðŸ’¾ Model saved to: ./models/ALE_Pong-v5-best_-7-20251126-1302-double_dqn_epsdec100000_rs5000_sync1000.dat\n",
      "Best reward updated -8.000 -> -7.370\n",
      "314000: done 609 games, reward -6.830, eps 0.01, speed 173.46 f/s, time 28.8 min\n",
      "ðŸ’¾ Model saved to: ./models/ALE_Pong-v5-best_-6-20251126-1304-double_dqn_epsdec100000_rs5000_sync1000.dat\n",
      "Best reward updated -7.370 -> -6.830\n",
      "352576: done 660 games, reward -6.230, eps 0.01, speed 166.65 f/s, time 32.6 min\n",
      "ðŸ’¾ Model saved to: ./models/ALE_Pong-v5-best_-6-20251126-1308-double_dqn_epsdec100000_rs5000_sync1000.dat\n",
      "Best reward updated -6.830 -> -6.230\n",
      "475840: done 820 games, reward -5.720, eps 0.01, speed 166.48 f/s, time 44.7 min\n",
      "ðŸ’¾ Model saved to: ./models/ALE_Pong-v5-best_-5-20251126-1320-double_dqn_epsdec100000_rs5000_sync1000.dat\n",
      "Best reward updated -6.230 -> -5.720\n",
      "508552: done 861 games, reward -5.150, eps 0.01, speed 176.54 f/s, time 47.9 min\n",
      "ðŸ’¾ Model saved to: ./models/ALE_Pong-v5-best_-5-20251126-1323-double_dqn_epsdec100000_rs5000_sync1000.dat\n",
      "Best reward updated -5.720 -> -5.150\n",
      "514391: done 868 games, reward -4.640, eps 0.01, speed 174.73 f/s, time 48.4 min\n",
      "ðŸ’¾ Model saved to: ./models/ALE_Pong-v5-best_-4-20251126-1324-double_dqn_epsdec100000_rs5000_sync1000.dat\n",
      "Best reward updated -5.150 -> -4.640\n",
      "764528: done 1172 games, reward -4.070, eps 0.01, speed 174.23 f/s, time 72.5 min\n",
      "ðŸ’¾ Model saved to: ./models/ALE_Pong-v5-best_-4-20251126-1348-double_dqn_epsdec100000_rs5000_sync1000.dat\n",
      "Best reward updated -4.640 -> -4.070\n",
      "781810: done 1193 games, reward -3.540, eps 0.01, speed 169.29 f/s, time 74.2 min\n",
      "ðŸ’¾ Model saved to: ./models/ALE_Pong-v5-best_-3-20251126-1349-double_dqn_epsdec100000_rs5000_sync1000.dat\n",
      "Best reward updated -4.070 -> -3.540\n",
      "839962: done 1260 games, reward -2.930, eps 0.01, speed 179.41 f/s, time 79.8 min\n",
      "ðŸ’¾ Model saved to: ./models/ALE_Pong-v5-best_-2-20251126-1355-double_dqn_epsdec100000_rs5000_sync1000.dat\n",
      "Best reward updated -3.540 -> -2.930\n",
      "894292: done 1319 games, reward -2.410, eps 0.01, speed 172.27 f/s, time 84.9 min\n",
      "ðŸ’¾ Model saved to: ./models/ALE_Pong-v5-best_-2-20251126-1400-double_dqn_epsdec100000_rs5000_sync1000.dat\n",
      "Best reward updated -2.930 -> -2.410\n",
      "912391: done 1340 games, reward -1.840, eps 0.01, speed 176.07 f/s, time 86.6 min\n",
      "ðŸ’¾ Model saved to: ./models/ALE_Pong-v5-best_-1-20251126-1402-double_dqn_epsdec100000_rs5000_sync1000.dat\n",
      "Best reward updated -2.410 -> -1.840\n",
      "1159291: done 1624 games, reward -1.300, eps 0.01, speed 171.29 f/s, time 110.7 min\n",
      "ðŸ’¾ Model saved to: ./models/ALE_Pong-v5-best_-1-20251126-1426-double_dqn_epsdec100000_rs5000_sync1000.dat\n",
      "Best reward updated -1.840 -> -1.300\n",
      "1176185: done 1644 games, reward -0.740, eps 0.01, speed 170.26 f/s, time 112.3 min\n",
      "ðŸ’¾ Model saved to: ./models/ALE_Pong-v5-best_0-20251126-1427-double_dqn_epsdec100000_rs5000_sync1000.dat\n",
      "Best reward updated -1.300 -> -0.740\n",
      "1189188: done 1659 games, reward -0.180, eps 0.01, speed 168.99 f/s, time 113.6 min\n",
      "ðŸ’¾ Model saved to: ./models/ALE_Pong-v5-best_0-20251126-1429-double_dqn_epsdec100000_rs5000_sync1000.dat\n",
      "Best reward updated -0.740 -> -0.180\n",
      "1216099: done 1689 games, reward 0.350, eps 0.01, speed 175.59 f/s, time 116.2 min\n",
      "ðŸ’¾ Model saved to: ./models/ALE_Pong-v5-best_0-20251126-1431-double_dqn_epsdec100000_rs5000_sync1000.dat\n",
      "Best reward updated -0.180 -> 0.350\n",
      "1237143: done 1713 games, reward 0.860, eps 0.01, speed 168.56 f/s, time 118.3 min\n",
      "ðŸ’¾ Model saved to: ./models/ALE_Pong-v5-best_0-20251126-1433-double_dqn_epsdec100000_rs5000_sync1000.dat\n",
      "Best reward updated 0.350 -> 0.860\n",
      "1297743: done 1782 games, reward 1.390, eps 0.01, speed 172.14 f/s, time 124.2 min\n",
      "ðŸ’¾ Model saved to: ./models/ALE_Pong-v5-best_1-20251126-1439-double_dqn_epsdec100000_rs5000_sync1000.dat\n",
      "Best reward updated 0.860 -> 1.390\n",
      "1314841: done 1802 games, reward 1.940, eps 0.01, speed 170.18 f/s, time 125.8 min\n",
      "ðŸ’¾ Model saved to: ./models/ALE_Pong-v5-best_1-20251126-1441-double_dqn_epsdec100000_rs5000_sync1000.dat\n",
      "Best reward updated 1.390 -> 1.940\n",
      "1334630: done 1825 games, reward 2.450, eps 0.01, speed 172.13 f/s, time 127.7 min\n",
      "ðŸ’¾ Model saved to: ./models/ALE_Pong-v5-best_2-20251126-1443-double_dqn_epsdec100000_rs5000_sync1000.dat\n",
      "Best reward updated 1.940 -> 2.450\n",
      "1733737: done 2289 games, reward 3.000, eps 0.01, speed 180.56 f/s, time 165.5 min\n",
      "ðŸ’¾ Model saved to: ./models/ALE_Pong-v5-best_3-20251126-1521-double_dqn_epsdec100000_rs5000_sync1000.dat\n",
      "Best reward updated 2.450 -> 3.000\n",
      "1764581: done 2326 games, reward 3.600, eps 0.01, speed 172.17 f/s, time 168.3 min\n",
      "ðŸ’¾ Model saved to: ./models/ALE_Pong-v5-best_3-20251126-1523-double_dqn_epsdec100000_rs5000_sync1000.dat\n",
      "Best reward updated 3.000 -> 3.600\n",
      "1778628: done 2342 games, reward 4.170, eps 0.01, speed 179.32 f/s, time 169.7 min\n",
      "ðŸ’¾ Model saved to: ./models/ALE_Pong-v5-best_4-20251126-1525-double_dqn_epsdec100000_rs5000_sync1000.dat\n",
      "Best reward updated 3.600 -> 4.170\n",
      "1796811: done 2363 games, reward 4.790, eps 0.01, speed 173.21 f/s, time 171.4 min\n",
      "ðŸ’¾ Model saved to: ./models/ALE_Pong-v5-best_4-20251126-1527-double_dqn_epsdec100000_rs5000_sync1000.dat\n",
      "Best reward updated 4.170 -> 4.790\n",
      "1871246: done 2451 games, reward 5.300, eps 0.01, speed 179.73 f/s, time 178.5 min\n",
      "ðŸ’¾ Model saved to: ./models/ALE_Pong-v5-best_5-20251126-1534-double_dqn_epsdec100000_rs5000_sync1000.dat\n",
      "Best reward updated 4.790 -> 5.300\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 29\u001b[39m\n\u001b[32m     26\u001b[39m frame_idx += \u001b[32m1\u001b[39m\n\u001b[32m     27\u001b[39m epsilon = \u001b[38;5;28mmax\u001b[39m(EPSILON_FINAL, EPSILON_START - frame_idx / EPSILON_DECAY_LAST_FRAME)\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m reward = agent.play_step(net, device, epsilon)\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m reward \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     31\u001b[39m     total_rewards.append(reward)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/myenv1/lib/python3.13/site-packages/torch/utils/_contextlib.py:120\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m func(*args, **kwargs)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 27\u001b[39m, in \u001b[36mAgent.play_step\u001b[39m\u001b[34m(self, net, device, epsilon)\u001b[39m\n\u001b[32m     24\u001b[39m     action = \u001b[38;5;28mint\u001b[39m(act_v.item())\n\u001b[32m     26\u001b[39m \u001b[38;5;66;03m# do step in the environment\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m new_state, reward, is_done, is_tr, _ = \u001b[38;5;28mself\u001b[39m.env.step(action)\n\u001b[32m     28\u001b[39m \u001b[38;5;28mself\u001b[39m.total_reward += reward\n\u001b[32m     30\u001b[39m exp = Experience(\n\u001b[32m     31\u001b[39m     state=\u001b[38;5;28mself\u001b[39m.state, action=action, reward=\u001b[38;5;28mfloat\u001b[39m(reward),\n\u001b[32m     32\u001b[39m     done_trunc=is_done \u001b[38;5;129;01mor\u001b[39;00m is_tr, new_state=new_state\n\u001b[32m     33\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/myenv1/lib/python3.13/site-packages/gymnasium/core.py:560\u001b[39m, in \u001b[36mObservationWrapper.step\u001b[39m\u001b[34m(self, action)\u001b[39m\n\u001b[32m    556\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstep\u001b[39m(\n\u001b[32m    557\u001b[39m     \u001b[38;5;28mself\u001b[39m, action: ActType\n\u001b[32m    558\u001b[39m ) -> \u001b[38;5;28mtuple\u001b[39m[WrapperObsType, SupportsFloat, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]]:\n\u001b[32m    559\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Modifies the :attr:`env` after calling :meth:`step` using :meth:`self.observation` on the returned observations.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m560\u001b[39m     observation, reward, terminated, truncated, info = \u001b[38;5;28mself\u001b[39m.env.step(action)\n\u001b[32m    561\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.observation(observation), reward, terminated, truncated, info\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/myenv1/lib/python3.13/site-packages/gymnasium/core.py:560\u001b[39m, in \u001b[36mObservationWrapper.step\u001b[39m\u001b[34m(self, action)\u001b[39m\n\u001b[32m    556\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstep\u001b[39m(\n\u001b[32m    557\u001b[39m     \u001b[38;5;28mself\u001b[39m, action: ActType\n\u001b[32m    558\u001b[39m ) -> \u001b[38;5;28mtuple\u001b[39m[WrapperObsType, SupportsFloat, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]]:\n\u001b[32m    559\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Modifies the :attr:`env` after calling :meth:`step` using :meth:`self.observation` on the returned observations.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m560\u001b[39m     observation, reward, terminated, truncated, info = \u001b[38;5;28mself\u001b[39m.env.step(action)\n\u001b[32m    561\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.observation(observation), reward, terminated, truncated, info\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/myenv1/lib/python3.13/site-packages/gymnasium/core.py:327\u001b[39m, in \u001b[36mWrapper.step\u001b[39m\u001b[34m(self, action)\u001b[39m\n\u001b[32m    323\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstep\u001b[39m(\n\u001b[32m    324\u001b[39m     \u001b[38;5;28mself\u001b[39m, action: WrapperActType\n\u001b[32m    325\u001b[39m ) -> \u001b[38;5;28mtuple\u001b[39m[WrapperObsType, SupportsFloat, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]]:\n\u001b[32m    326\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Uses the :meth:`step` of the :attr:`env` that can be overwritten to change the returned data.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m327\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.env.step(action)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/myenv1/lib/python3.13/site-packages/gymnasium/core.py:560\u001b[39m, in \u001b[36mObservationWrapper.step\u001b[39m\u001b[34m(self, action)\u001b[39m\n\u001b[32m    556\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstep\u001b[39m(\n\u001b[32m    557\u001b[39m     \u001b[38;5;28mself\u001b[39m, action: ActType\n\u001b[32m    558\u001b[39m ) -> \u001b[38;5;28mtuple\u001b[39m[WrapperObsType, SupportsFloat, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]]:\n\u001b[32m    559\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Modifies the :attr:`env` after calling :meth:`step` using :meth:`self.observation` on the returned observations.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m560\u001b[39m     observation, reward, terminated, truncated, info = \u001b[38;5;28mself\u001b[39m.env.step(action)\n\u001b[32m    561\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.observation(observation), reward, terminated, truncated, info\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/myenv1/lib/python3.13/site-packages/gymnasium/core.py:327\u001b[39m, in \u001b[36mWrapper.step\u001b[39m\u001b[34m(self, action)\u001b[39m\n\u001b[32m    323\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstep\u001b[39m(\n\u001b[32m    324\u001b[39m     \u001b[38;5;28mself\u001b[39m, action: WrapperActType\n\u001b[32m    325\u001b[39m ) -> \u001b[38;5;28mtuple\u001b[39m[WrapperObsType, SupportsFloat, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]]:\n\u001b[32m    326\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Uses the :meth:`step` of the :attr:`env` that can be overwritten to change the returned data.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m327\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.env.step(action)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/myenv1/lib/python3.13/site-packages/stable_baselines3/common/atari_wrappers.py:112\u001b[39m, in \u001b[36mEpisodicLifeEnv.step\u001b[39m\u001b[34m(self, action)\u001b[39m\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, action: \u001b[38;5;28mint\u001b[39m) -> AtariStepReturn:\n\u001b[32m--> \u001b[39m\u001b[32m112\u001b[39m     obs, reward, terminated, truncated, info = \u001b[38;5;28mself\u001b[39m.env.step(action)\n\u001b[32m    113\u001b[39m     \u001b[38;5;28mself\u001b[39m.was_real_done = terminated \u001b[38;5;129;01mor\u001b[39;00m truncated\n\u001b[32m    114\u001b[39m     \u001b[38;5;66;03m# check current lives, make loss of life terminal,\u001b[39;00m\n\u001b[32m    115\u001b[39m     \u001b[38;5;66;03m# then update lives to handle bonus lives\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/myenv1/lib/python3.13/site-packages/stable_baselines3/common/atari_wrappers.py:178\u001b[39m, in \u001b[36mMaxAndSkipEnv.step\u001b[39m\u001b[34m(self, action)\u001b[39m\n\u001b[32m    176\u001b[39m terminated = truncated = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    177\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m._skip):\n\u001b[32m--> \u001b[39m\u001b[32m178\u001b[39m     obs, reward, terminated, truncated, info = \u001b[38;5;28mself\u001b[39m.env.step(action)\n\u001b[32m    179\u001b[39m     done = terminated \u001b[38;5;129;01mor\u001b[39;00m truncated\n\u001b[32m    180\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m i == \u001b[38;5;28mself\u001b[39m._skip - \u001b[32m2\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/myenv1/lib/python3.13/site-packages/gymnasium/wrappers/common.py:393\u001b[39m, in \u001b[36mOrderEnforcing.step\u001b[39m\u001b[34m(self, action)\u001b[39m\n\u001b[32m    391\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._has_reset:\n\u001b[32m    392\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ResetNeeded(\u001b[33m\"\u001b[39m\u001b[33mCannot call env.step() before calling env.reset()\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m393\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().step(action)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/myenv1/lib/python3.13/site-packages/gymnasium/core.py:327\u001b[39m, in \u001b[36mWrapper.step\u001b[39m\u001b[34m(self, action)\u001b[39m\n\u001b[32m    323\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstep\u001b[39m(\n\u001b[32m    324\u001b[39m     \u001b[38;5;28mself\u001b[39m, action: WrapperActType\n\u001b[32m    325\u001b[39m ) -> \u001b[38;5;28mtuple\u001b[39m[WrapperObsType, SupportsFloat, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]]:\n\u001b[32m    326\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Uses the :meth:`step` of the :attr:`env` that can be overwritten to change the returned data.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m327\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.env.step(action)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/myenv1/lib/python3.13/site-packages/gymnasium/wrappers/common.py:285\u001b[39m, in \u001b[36mPassiveEnvChecker.step\u001b[39m\u001b[34m(self, action)\u001b[39m\n\u001b[32m    283\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m env_step_passive_checker(\u001b[38;5;28mself\u001b[39m.env, action)\n\u001b[32m    284\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m285\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.env.step(action)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/myenv1/lib/python3.13/site-packages/ale_py/env.py:310\u001b[39m, in \u001b[36mAtariEnv.step\u001b[39m\u001b[34m(self, action)\u001b[39m\n\u001b[32m    307\u001b[39m is_terminal = \u001b[38;5;28mself\u001b[39m.ale.game_over(with_truncation=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    308\u001b[39m is_truncated = \u001b[38;5;28mself\u001b[39m.ale.game_truncated()\n\u001b[32m--> \u001b[39m\u001b[32m310\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._get_obs(), reward, is_terminal, is_truncated, \u001b[38;5;28mself\u001b[39m._get_info()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/myenv1/lib/python3.13/site-packages/ale_py/env.py:329\u001b[39m, in \u001b[36mAtariEnv._get_obs\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    327\u001b[39m     image_obs = \u001b[38;5;28mself\u001b[39m.ale.getRAM()\n\u001b[32m    328\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._obs_type == \u001b[33m\"\u001b[39m\u001b[33mrgb\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m329\u001b[39m     image_obs = \u001b[38;5;28mself\u001b[39m.ale.getScreenRGB()\n\u001b[32m    330\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._obs_type == \u001b[33m\"\u001b[39m\u001b[33mgrayscale\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    331\u001b[39m     image_obs = \u001b[38;5;28mself\u001b[39m.ale.getScreenGrayscale()\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "model_comment = f\"double_dqn_epsdec{EPSILON_DECAY_LAST_FRAME}_rs{REPLAY_START_SIZE}_sync{SYNC_TARGET_FRAMES}\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "env = make_env(env_name)\n",
    "net = DQN(env.observation_space.shape, env.action_space.n).to(device)\n",
    "tgt_net = DQN(env.observation_space.shape, env.action_space.n).to(device)\n",
    "writer = SummaryWriter(comment=f\"-{env_name}-{model_comment}\")\n",
    "print(net)\n",
    "\n",
    "buffer = ExperienceBuffer(REPLAY_SIZE)\n",
    "agent = Agent(env, buffer)\n",
    "epsilon = EPSILON_START\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr=LEARNING_RATE)\n",
    "total_rewards = []\n",
    "frame_idx = 0\n",
    "ts_frame = 0\n",
    "ts = time.time()\n",
    "best_m_reward = None\n",
    "\n",
    "print(\"loop START\")\n",
    "start_time = time.time()\n",
    "while True:\n",
    "    frame_idx += 1\n",
    "    epsilon = max(EPSILON_FINAL, EPSILON_START - frame_idx / EPSILON_DECAY_LAST_FRAME)\n",
    "\n",
    "    reward = agent.play_step(net, device, epsilon)\n",
    "    if reward is not None:\n",
    "        total_rewards.append(reward)\n",
    "        speed = (frame_idx - ts_frame) / (time.time() - ts)\n",
    "        elapsed = time.time() - start_time  # in seconds\n",
    "        ts_frame = frame_idx\n",
    "        ts = time.time()\n",
    "        m_reward = np.mean(total_rewards[-100:])\n",
    "   \n",
    "        writer.add_scalar(\"epsilon\", epsilon, frame_idx)\n",
    "        writer.add_scalar(\"speed\", speed, frame_idx)\n",
    "        writer.add_scalar(\"reward_100\", m_reward, frame_idx)\n",
    "        writer.add_scalar(\"reward\", reward, frame_idx)\n",
    "        if best_m_reward is None or m_reward > best_m_reward + SAVE_EPSILON:\n",
    "            print(f\"{frame_idx}: done {len(total_rewards)} games, reward {m_reward:.3f}, \"\n",
    "                f\"eps {epsilon:.2f}, speed {speed:.2f} f/s, time {elapsed/60:.1f} min\")\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d-%H%M\")\n",
    "            model_filename = f\"{safe_env_name}-best_{int(m_reward)}-{timestamp}-{model_comment}.dat\"\n",
    "\n",
    "            # Save to both paths <-----------------------\n",
    "            model_path = os.path.join(save_dir, model_filename)\n",
    "            torch.save(net.state_dict(), model_path)\n",
    "            print(f\" Model saved to: {model_path}\")\n",
    "            # Adjust <-----------------------------------\n",
    "            if best_m_reward is not None:\n",
    "                print(f\"Best reward updated {best_m_reward:.3f} -> {m_reward:.3f}\")\n",
    "            best_m_reward = m_reward\n",
    "        if m_reward > MEAN_REWARD_BOUND:\n",
    "            print(\"Solved in %d frames!\" % frame_idx)\n",
    "            break\n",
    "    if len(buffer) < REPLAY_START_SIZE:\n",
    "        continue\n",
    "    if frame_idx % SYNC_TARGET_FRAMES == 0:\n",
    "        tgt_net.load_state_dict(net.state_dict())\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    batch = buffer.sample(BATCH_SIZE)\n",
    "    loss_t = calc_loss_dDQN(batch, net, tgt_net, device)\n",
    "    loss_t.backward()\n",
    "    optimizer.step()\n",
    "env.close()\n",
    "writer.close()\n",
    "\n",
    "print(\"the END of the loop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "======================================================================\n",
      "STEP 1: TESTING DOUBLE DQN\n",
      "======================================================================\n",
      "Best model found: ./models/ALE_Pong-v5-best_5-20251126-1534-double_dqn_epsdec100000_rs5000_sync1000.dat\n",
      "Model reward: 5\n",
      "Creating environment ALE/Pong-v5\n",
      "\n",
      "Playing 10 test games...\n",
      "  Game  1:   9\n",
      "  Game  2:   2\n",
      "  Game  3:  11\n",
      "  Game  4:  -1\n",
      "  Game  5:   3\n",
      "  Game  6:  11\n",
      "  Game  7:  -1\n",
      "  Game  8:   6\n",
      "  Game  9:  13\n",
      "  Game 10:   9\n",
      "\n",
      "======================================================================\n",
      "DOUBLE DQN TEST RESULTS\n",
      "======================================================================\n",
      "Average Reward:    6.2\n",
      "Std Deviation:     4.89\n",
      "Best Game:         13\n",
      "Worst Game:        -1\n",
      "Games Won (>0):    8/10\n",
      "======================================================================\n",
      "ðŸ“Š Double DQN test average: 6.2\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# STEP 1: Test Double DQN Agent\n",
    "# ============================================================\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device: \" + str(device))\n",
    "\n",
    "# Auto-find best Double DQN model in folder\n",
    "models_dir = \"./models\"\n",
    "best_reward = -float('inf')\n",
    "ddqn_model_path = None\n",
    "\n",
    "for filename in os.listdir(models_dir):\n",
    "    if \"double_dqn\" in filename and filename.endswith(\".dat\"):\n",
    "        match = re.search(r'best_(-?\\d+)-', filename)\n",
    "        if match:\n",
    "            reward = int(match.group(1))\n",
    "            if reward > best_reward:\n",
    "                best_reward = reward\n",
    "                ddqn_model_path = os.path.join(models_dir, filename)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"STEP 1: TESTING DOUBLE DQN\")\n",
    "print(\"=\"*70)\n",
    "print(\"Best model found: \" + str(ddqn_model_path))\n",
    "print(\"Model reward: \" + str(best_reward))\n",
    "\n",
    "# Load Double DQN model\n",
    "test_env = make_env(DEFAULT_ENV_NAME)\n",
    "ddqn_net = DQN(test_env.observation_space.shape, test_env.action_space.n).to(device)\n",
    "\n",
    "# FIXED: Add map_location to handle GPU/CPU mismatch\n",
    "ddqn_net.load_state_dict(torch.load(ddqn_model_path, map_location=device))\n",
    "ddqn_net.eval()\n",
    "\n",
    "# Test on 10 games\n",
    "print(\"\\nPlaying 10 test games...\")\n",
    "test_rewards = []\n",
    "for game in range(10):\n",
    "    state, _ = test_env.reset()\n",
    "    episode_reward = 0\n",
    "    done = False\n",
    "    \n",
    "    while not done:\n",
    "        state_v = torch.tensor(np.array([state])).to(device)\n",
    "        with torch.no_grad():\n",
    "            q_vals = ddqn_net(state_v)\n",
    "            action = q_vals.max(1)[1].item()\n",
    "        \n",
    "        state, reward, terminated, truncated, _ = test_env.step(action)\n",
    "        episode_reward += reward\n",
    "        done = terminated or truncated\n",
    "    \n",
    "    test_rewards.append(episode_reward)\n",
    "    print(\"  Game \" + str(game+1).rjust(2) + \": \" + str(int(episode_reward)).rjust(3))\n",
    "\n",
    "test_env.close()\n",
    "\n",
    "# Results\n",
    "ddqn_test_avg = np.mean(test_rewards)\n",
    "ddqn_test_std = np.std(test_rewards)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"DOUBLE DQN TEST RESULTS\")\n",
    "print(\"=\"*70)\n",
    "print(\"Average Reward:    \" + str(round(ddqn_test_avg, 2)))\n",
    "print(\"Std Deviation:     \" + str(round(ddqn_test_std, 2)))\n",
    "print(\"Best Game:         \" + str(int(max(test_rewards))))\n",
    "print(\"Worst Game:        \" + str(int(min(test_rewards))))\n",
    "print(\"Games Won (>0):    \" + str(sum(1 for r in test_rewards if r > 0)) + \"/10\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"ðŸ“Š Double DQN test average: \" + str(round(ddqn_test_avg, 2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "======================================================================\n",
      "STEP 2: RECORDING DOUBLE DQN VIDEOS\n",
      "======================================================================\n",
      "Using model: ./models/ALE_Pong-v5-best_5-20251126-1534-double_dqn_epsdec100000_rs5000_sync1000.dat\n",
      "\n",
      "[1/2] Recording early/random behavior...\n",
      "Creating environment ALE/Pong-v5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/emil/miniconda3/envs/myenv1/lib/python3.13/site-packages/gymnasium/wrappers/rendering.py:283: UserWarning: \u001b[33mWARN: Overwriting existing videos at /home/emil/Desktop/project/videos/ddqn_early folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Recorded! Reward: -20\n",
      "\n",
      "[2/2] Recording trained Double DQN behavior...\n",
      "Creating environment ALE/Pong-v5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/emil/miniconda3/envs/myenv1/lib/python3.13/site-packages/gymnasium/wrappers/rendering.py:283: UserWarning: \u001b[33mWARN: Overwriting existing videos at /home/emil/Desktop/project/videos/ddqn_learned folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      âœ… Recorded! Reward: 10\n",
      "\n",
      "======================================================================\n",
      "DOUBLE DQN VIDEOS COMPLETE\n",
      "======================================================================\n",
      "Location:\n",
      "  Early:   ./videos/ddqn_early/\n",
      "  Learned: ./videos/ddqn_learned/\n",
      "\n",
      "Reward Comparison:\n",
      "  Random:       -20\n",
      "  Trained:      10\n",
      "  Improvement:  30 points\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# STEP 2: Record Double DQN Videos (FIXED)\n",
    "# ============================================================\n",
    "from gymnasium.wrappers import RecordVideo\n",
    "import os\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device: \" + str(device))\n",
    "\n",
    "# Create video directories\n",
    "os.makedirs('./videos/ddqn_early', exist_ok=True)\n",
    "os.makedirs('./videos/ddqn_learned', exist_ok=True)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"STEP 2: RECORDING DOUBLE DQN VIDEOS\")\n",
    "print(\"=\"*70)\n",
    "print(\"Using model: \" + str(ddqn_model_path))\n",
    "\n",
    "# VIDEO 1: Early/Random Behavior\n",
    "print(\"\\n[1/2] Recording early/random behavior...\")\n",
    "video_env = make_env(DEFAULT_ENV_NAME, render_mode=\"rgb_array\")\n",
    "video_env = RecordVideo(\n",
    "    video_env,\n",
    "    video_folder='./videos/ddqn_early',\n",
    "    episode_trigger=lambda x: x == 0,\n",
    "    name_prefix=\"ddqn-early\"\n",
    ")\n",
    "\n",
    "state, _ = video_env.reset()\n",
    "done = False\n",
    "early_reward = 0\n",
    "while not done:\n",
    "    action = video_env.action_space.sample()  # Random\n",
    "    state, reward, terminated, truncated, _ = video_env.step(action)\n",
    "    early_reward += reward\n",
    "    done = terminated or truncated\n",
    "video_env.close()\n",
    "print(\"       Recorded! Reward: \" + str(int(early_reward)))\n",
    "\n",
    "# VIDEO 2: Trained Double DQN Behavior\n",
    "print(\"\\n[2/2] Recording trained Double DQN behavior...\")\n",
    "video_env = make_env(DEFAULT_ENV_NAME, render_mode=\"rgb_array\")\n",
    "video_env = RecordVideo(\n",
    "    video_env,\n",
    "    video_folder='./videos/ddqn_learned',\n",
    "    episode_trigger=lambda x: x == 0,\n",
    "    name_prefix=\"ddqn-learned\"\n",
    ")\n",
    "\n",
    "ddqn_net = DQN(video_env.observation_space.shape, video_env.action_space.n).to(device)\n",
    "\n",
    "# FIXED: Add map_location to handle GPU/CPU mismatch\n",
    "ddqn_net.load_state_dict(torch.load(ddqn_model_path, map_location=device))\n",
    "ddqn_net.eval()\n",
    "\n",
    "state, _ = video_env.reset()\n",
    "done = False\n",
    "learned_reward = 0\n",
    "while not done:\n",
    "    state_v = torch.tensor(np.array([state])).to(device)\n",
    "    with torch.no_grad():\n",
    "        q_vals = ddqn_net(state_v)\n",
    "        action = q_vals.max(1)[1].item()\n",
    "    \n",
    "    state, reward, terminated, truncated, _ = video_env.step(action)\n",
    "    learned_reward += reward\n",
    "    done = terminated or truncated\n",
    "video_env.close()\n",
    "print(\"      âœ… Recorded! Reward: \" + str(int(learned_reward)))\n",
    "\n",
    "# Summary\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"DOUBLE DQN VIDEOS COMPLETE\")\n",
    "print(\"=\"*70)\n",
    "print(\"Location:\")\n",
    "print(\"  Early:   ./videos/ddqn_early/\")\n",
    "print(\"  Learned: ./videos/ddqn_learned/\")\n",
    "print(\"\\nReward Comparison:\")\n",
    "print(\"  Random:       \" + str(int(early_reward)))\n",
    "print(\"  Trained:      \" + str(int(learned_reward)))\n",
    "print(\"  Improvement:  \" + str(int(learned_reward - early_reward)) + \" points\")\n",
    "print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "FINAL COMPARISON: BASELINE DQN vs DOUBLE DQN\n",
      "======================================================================\n",
      "\n",
      "ðŸ“Š TEST RESULTS (10 games each):\n",
      "--------------------------------------------------\n",
      "                    Baseline DQN    Double DQN\n",
      "--------------------------------------------------\n",
      "Average Reward:          8.3              0.1\n",
      "Std Deviation:           6.9              7.4\n",
      "--------------------------------------------------\n",
      "\n",
      "ðŸ† Winner: Baseline DQN (+8.2 avg reward)\n",
      "======================================================================\n",
      "\n",
      "ðŸ“ VIDEO LOCATIONS:\n",
      "  Baseline Early:     ./videos/baseline_early/\n",
      "  Baseline Learned:   ./videos/baseline_learned/\n",
      "  Double DQN Early:   ./videos/ddqn_early/\n",
      "  Double DQN Learned: ./videos/ddqn_learned/\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# STEP 3: Compare Baseline DQN vs Double DQN\n",
    "# ============================================================\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"FINAL COMPARISON: BASELINE DQN vs DOUBLE DQN\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nðŸ“Š TEST RESULTS (10 games each):\")\n",
    "print(\"-\"*50)\n",
    "print(\"                    Baseline DQN    Double DQN\")\n",
    "print(\"-\"*50)\n",
    "print(\"Average Reward:     \" + str(round(baseline_test_avg, 2)).rjust(8) + \"         \" + str(round(ddqn_test_avg, 2)).rjust(8))\n",
    "print(\"Std Deviation:      \" + str(round(baseline_test_std, 2)).rjust(8) + \"         \" + str(round(ddqn_test_std, 2)).rjust(8))\n",
    "print(\"-\"*50)\n",
    "\n",
    "if ddqn_test_avg > baseline_test_avg:\n",
    "    winner = \"Double DQN\"\n",
    "    diff = ddqn_test_avg - baseline_test_avg\n",
    "else:\n",
    "    winner = \"Baseline DQN\"\n",
    "    diff = baseline_test_avg - ddqn_test_avg\n",
    "\n",
    "print(\"\\nðŸ† Winner: \" + winner + \" (+\" + str(round(diff, 2)) + \" avg reward)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nðŸ“ VIDEO LOCATIONS:\")\n",
    "print(\"  Baseline Early:     ./videos/baseline_early/\")\n",
    "print(\"  Baseline Learned:   ./videos/baseline_learned/\")\n",
    "print(\"  Double DQN Early:   ./videos/ddqn_early/\")\n",
    "print(\"  Double DQN Learned: ./videos/ddqn_learned/\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for TensorBoard logs...\n",
      "--------------------------------------------------\n",
      "Found: Nov26_08-59-08_EmilDesktop-ALE/Pong-v5-test_epsdec100000_rs5000_sync1000\n",
      "  Available tags: ['epsilon', 'speed', 'reward_100', 'reward']\n",
      "   Plotted successfully\n",
      "Found: Nov26_12-35-36_EmilDesktop-ALE/Pong-v5-double_dqn_epsdec100000_rs5000_sync1000\n",
      "  Available tags: ['epsilon', 'speed', 'reward_100', 'reward']\n",
      "   Plotted successfully\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Plot saved to learning_curves.png\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# PLOT LEARNING CURVES\n",
    "# ============================================================\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorboard.backend.event_processing.event_accumulator import EventAccumulator\n",
    "\n",
    "runs_dir = \"./runs\"\n",
    "\n",
    "def extract_tensorboard_data(log_dir):\n",
    "    event_acc = EventAccumulator(log_dir)\n",
    "    event_acc.Reload()\n",
    "    \n",
    "    # Try different possible tag names\n",
    "    available_tags = event_acc.Tags()['scalars']\n",
    "    print(\"  Available tags: \" + str(available_tags))\n",
    "    \n",
    "    if 'reward_100' in available_tags:\n",
    "        reward_data = event_acc.Scalars('reward_100')\n",
    "    elif 'reward' in available_tags:\n",
    "        reward_data = event_acc.Scalars('reward')\n",
    "    else:\n",
    "        return None, None\n",
    "    \n",
    "    steps = [x.step for x in reward_data]\n",
    "    rewards = [x.value for x in reward_data]\n",
    "    return steps, rewards\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "print(\"Searching for TensorBoard logs...\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "for folder in os.listdir(runs_dir):\n",
    "    folder_path = os.path.join(runs_dir, folder)\n",
    "    if os.path.isdir(folder_path):\n",
    "        # Check subfolders for event files\n",
    "        for subfolder in os.listdir(folder_path):\n",
    "            subfolder_path = os.path.join(folder_path, subfolder)\n",
    "            if os.path.isdir(subfolder_path):\n",
    "                # Look for event files in subfolder\n",
    "                for file in os.listdir(subfolder_path):\n",
    "                    if file.startswith(\"events.out\"):\n",
    "                        print(\"Found: \" + folder + \"/\" + subfolder)\n",
    "                        try:\n",
    "                            steps, rewards = extract_tensorboard_data(subfolder_path)\n",
    "                            if steps and rewards:\n",
    "                                if \"double_dqn\" in subfolder.lower():\n",
    "                                    label = \"Double DQN\"\n",
    "                                    color = \"blue\"\n",
    "                                else:\n",
    "                                    label = \"Baseline DQN\"\n",
    "                                    color = \"orange\"\n",
    "                                plt.plot(steps, rewards, label=label, color=color, alpha=0.7)\n",
    "                                print(\"   Plotted successfully\")\n",
    "                        except Exception as e:\n",
    "                            print(\"   Error: \" + str(e))\n",
    "\n",
    "plt.xlabel(\"Frames\", fontsize=12)\n",
    "plt.ylabel(\"Mean Reward (last 100 episodes)\", fontsize=12)\n",
    "plt.title(\"Baseline DQN vs Double DQN Learning Curves - Pong\", fontsize=14)\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.axhline(y=0, color='gray', linestyle='--', alpha=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"learning_curves.png\", dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n Plot saved to learning_curves.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================================================================\n",
      "HYPERPARAMETER TUNING LOG\n",
      "===============================================================================================\n",
      "\n",
      "COMPARISON: Default Starter Code vs Final Configuration\n",
      "--------------------------------------------------------------------------------\n",
      "| # | Parameter                | Original   | Updated   | Why I Changed It               |\n",
      "|---|--------------------------|------------|-----------|--------------------------------|\n",
      "| 1 | BATCH_SIZE               | 32         | 64        | Better gradient estimates      |\n",
      "| 2 | REPLAY_SIZE              | 10,000     | 50,000    | More diverse experiences       |\n",
      "| 3 | LEARNING_RATE            | 1e-4       | 2.5e-4    | Faster convergence             |\n",
      "| 4 | SYNC_TARGET_FRAMES       | 500        | 1,000     | More stable target updates     |\n",
      "| 5 | REPLAY_START_SIZE        | 1,000      | 5,000     | Better initial sample diversity|\n",
      "| 6 | EPSILON_DECAY_LAST_FRAME | 10,000     | 100,000   | More exploration time          |\n",
      "| 7 | MEAN_REWARD_BOUND        | 5          | 18        | Train until nearly solved      |\n",
      "| 8 | Loss Function            | DQN        | Double DQN| Reduce Q-value overestimation  |\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "RESULTS:\n",
      "- Baseline DQN: Best reward +6, Test avg: +8.3\n",
      "- Double DQN:   Best reward +5, Test avg: +0.1\n",
      "- Winner: Baseline DQN (with same hyperparameters)\n",
      "\n",
      "KEY INSIGHT:\n",
      "Both Baseline DQN and Double DQN used IDENTICAL final hyperparameters.\n",
      "The only difference was the loss function (calc_loss vs calc_loss_dDQN).\n",
      "This ensures a FAIR comparison between the two methods.\n",
      "\n",
      "===============================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# HYPERPARAMETER TUNING LOG\n",
    "# ============================================================\n",
    "print(\"=\"*95)\n",
    "print(\"HYPERPARAMETER TUNING LOG\")\n",
    "print(\"=\"*95)\n",
    "print(\"\"\"\n",
    "COMPARISON: Default Starter Code vs Final Configuration\n",
    "--------------------------------------------------------------------------------\n",
    "| # | Parameter                | Original   | Updated   | Why I Changed It               |\n",
    "|---|--------------------------|------------|-----------|--------------------------------|\n",
    "| 1 | BATCH_SIZE               | 32         | 64        | Better gradient estimates      |\n",
    "| 2 | REPLAY_SIZE              | 10,000     | 50,000    | More diverse experiences       |\n",
    "| 3 | LEARNING_RATE            | 1e-4       | 2.5e-4    | Faster convergence             |\n",
    "| 4 | SYNC_TARGET_FRAMES       | 500        | 1,000     | More stable target updates     |\n",
    "| 5 | REPLAY_START_SIZE        | 1,000      | 5,000     | Better initial sample diversity|\n",
    "| 6 | EPSILON_DECAY_LAST_FRAME | 10,000     | 100,000   | More exploration time          |\n",
    "| 7 | MEAN_REWARD_BOUND        | 5          | 18        | Train until nearly solved      |\n",
    "| 8 | Loss Function            | DQN        | Double DQN| Reduce Q-value overestimation  |\n",
    "--------------------------------------------------------------------------------\n",
    "\n",
    "RESULTS:\n",
    "- Baseline DQN: Best reward +6, Test avg: +8.3\n",
    "- Double DQN:   Best reward +5, Test avg: +0.1\n",
    "- Winner: Baseline DQN (with same hyperparameters)\n",
    "\n",
    "KEY INSIGHT:\n",
    "Both Baseline DQN and Double DQN used IDENTICAL final hyperparameters.\n",
    "The only difference was the loss function (calc_loss vs calc_loss_dDQN).\n",
    "This ensures a FAIR comparison between the two methods.\n",
    "\"\"\")\n",
    "print(\"=\"*95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPcmqJUbJp0J71eKFUjK+lM",
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
